---
title: ICAPS 2022 Workshop on Deception Against Planning Systems and Planning in Adversarial Conditions (DAPSPAC)
layout: page
---
<div class="container">
  <div class="row">
    <div class="3u 12u(mobile) important(mobile)">
      <section>
        <header>
          <h3 class="top">Dates </h3>
        </header>
        <ul class="check-list">
          <li><s>Friday, April 2nd, 2022</s> - Submissions Due</li>
          <li><s>Friday, April 30th, 2022</s> - Notification</li>
          <li><strong>Friday, June 10th, 2022</strong> - Camera-ready Due</li>
          <li><strong>June 14, 2022</strong> - Workshop Date</li>
        </ul>
      </section>
      {% include workshops.html %}
    </div>
  <div class="9u 12u(mobile)">
    <section>
      <header>
        <h1 class="top">DAPSPAC</h1>
        <h2>2022 Workshop on Deception Against Planning Systems and Planning in Adversarial Conditions (DAPSPAC)</h2>

        <p>
        An ICAPS'22 Workshop<br/>
        Singapore Management University, Singapore<br/>
        June 14th, 2022
        </p>
      </header>
<p>
  Fielded applications of planning must interact with a world that can be inexplicably hostile in unexpected ways. Game theoretic means of handling adversarial environments are both computationally expensive and impose their own assumptions which can be violated or exploited. This makes understanding how planning techniques react to provocations and false information a critical requirement for planning system deployments.
  The workshop will look at both sides of the problem &mdash; from characterizing attacks and vulnerabilities to proposed methods for detecting and mitigating threats.
  
</p>

<p>
  Topics of interest include:
</p>

<ul>
  <li>Use cases and techniques for effective deception against planning systems</li>
  <li>Techniques for identifying and reacting to adversarial conditions</li>
  <li>Theoretical foundations and results for deception and robustness</li>
  <li>Analysis of robustness and stability of planning frameworks, including planning engines and corresponding knowledge models</li>
  <li>Validation and Verification of planning systems deployed in adversarial environment</li>
  <li>Relationships between game theory, automated planning, and applications of theory to planning system deployment</li>
  <li>Adversary modeling, both for evaluating the effect of deception on an actor and identifying adversarial inputs</li>
  <li>Applications of planning in adversarial conditions, e.g., cybersecurity operations</li>
</ul>

<h3>Invited Talks</h3>
             
<div class="row">
  <div class="12u 12u(mobile)">
    <div class="row">
      <div class="2u 3u(mobile)"><br />
        <img src="Simon_Parkinson.jpeg" alt="Simon Parkinson" class="profile-image"/>
      </div>
      <div class="10u 12u(mobile)">
        <h3 class="invited-name">Simon Parkinson</h3>
        <h4 class="invited-title">How cyberattacks can facilitate deceptive behaviour in autonomous systems</h4>
        <p class="abstract-text">Autonomous systems are deployed to manage dynamic, complex systems which include multiple human and machine actors. One significant application relevant to this talk is that of vehicle control. In such systems, there is a great opportunity for actors to take specific actions to initiate deceptive behaviours. This could be to deliberately impact autonomous systems to achieve the desired outcome, which could be malicious or for personal gain. There are many different types of deceptive behaviour, and in this talk, a classification framework is presented that defines the multiple deception types, providing examples of their impact on managing traffic infrastructure. For an adversary actor to achieve deceptive behaviours, the actor must establish the technical means to have the desired impact on the autonomous system. This talk specifically investigates how different types of cyberattacks can be performed, and how even an easy to execute attack can facilitate significant deceptive behaviours. Finally, the classification framework is extended to define how deceptive behaviours can result from a cyberattack, and how their impact can be measured and used to prioritise their mitigation.</p>
        <p class="abstract-text"><strong>Bio:</strong> Simon Parkinson is an Associate Professor of Cyber Security at the University of Huddersfield. He has been exploring topics on the interface between AI and Cyber Security for over a decade and has secured funds to undertake research and knowledge exchange from sources such as the UK’s Engineering and Physical Sciences Research Council, Innovate UK, and Defence Science and Technology Laboratory. One such example focused on understanding Cyber Security threats facing Connected and Autonomous Vehicles. He has published on this topic in leading journals and conferences. He has served as track chair and organised workshops at the ICAPS conference and is a serving member of an advisory group to regional law enforcement. He has delivered invited seminars for the UK Government on connected and autonomous vehicles and Cyber Security and global manufacturing organisations such as Alba Aluminium, Bahrain.</p>
      </div>
    </div>  <!-- closes row -->
  </div>  <!-- closes 12u 12u(mobile) -->
</div>  <!-- closes row -->
    
<div class="row">
  <div class="12u 12u(mobile)">
    <div class="row">
      <div class="2u 3u(mobile)"><br />
        <img src="Ehab_Al-Shaer.jpg" alt="Ehab Al-Shaer" class="profile-image"/>
      </div>
      <div class="10u 12u(mobile)">
        <h3 class="invited-name">Ehab Al-Shaer</h3>
        <h4 class="invited-title">Autonomous Cyber Deception -- Foundations and Practices</h4>
        <p class="abstract-text">The ultimate objective of cyber deception is to mislead adversaries from reaching the ``true" targets and at the same time to engage them to learn new attack tactics and techniques. Most of the existing deception solutions are operationally expensive, yet easily discoverable by attackers because they lack dynamism and adaptively. Autonomous cyber deception provides highly adaptive and embedded deception that can dynamically create and orchestrate honey resources appropriately to cope with dynamic behavior of the Advanced Persistent Threats (APTs).
        <br/>
        In this talk, we will presents our research experience in developing the theoretical foundation, and prototype implementation and evaluation of optimal planning for autonomous cyber deception.
          The goal is enable cyber deception agents that reside in any production systems to automatically create and orchestrate the deception ploys to steer and mislead the malware or APT attacks to the desired goal without human interaction. The deception ploys are dynamically composed based on the deception planning while ensuring safe yet fast deployment and orchestration of deceptive course-of-actions. We will show the evaluation of the system to deceive APT information stealers, ransomware, and Remote Access Trojans (RAT) within a few seconds and with minimum cost.</p>
        <p class="abstract-text"><strong>Bio:</strong>Dr. Al-Shaer is a Distinguished Research Fellow at Institute of Software Research (ISR) in the School of Computer Science and Faculty Member of CyLab at Carnegie Mellon University. Dr. Al-Shaer's key area of research is autonomous cyber defense, formal methods for security configuration, resilience of cyber and cyber-psychical, data analytics for cybersecurity, and cyber agility for deterrence and deception. Dr. Al-Shaer has edited/co-edited more than 9 books and book chapters, published more than 250 refereed articles. He was designated by the Department of Defense (DoD) as a Subject Matter Expert (SME) on security analytics and automation in 2011, Distinguished Career Professor in INI/CMU, IBM Faculty Award in 2012, and UNC Charlotte Faculty Research Award in 2013. Dr Al-Shaer was a general Chair, TPC chair and keynote speaker, and panelist in major conferences in this area including ACM CCS, IEEE IM 2007, IEEE POLICY 2008, and others.</p>
      </div>
    </div>  <!-- closes row -->
  </div>  <!-- closes 12u 12u(mobile) -->
</div>  <!-- closes row -->
    

<h3>Schedule</h3>
<div id="schedule">





  <h3>June 14 &mdash; 14:00-19:00(UTC) 10:00-15:00(EDT) 00:00-05:00(Canberra)</h3>
  <table class="schedule">
    <tr>
      <td class="time">14:00</td>
      <td class="opening-remarks">
        <h4>Workshop opening</h4>
      </td>
    </tr>
    <tr>
      <td class="time">14:10</td>
      <td class="invited-talk">
        <h4>Keynote: Simon Parkinson. How cyberattacks can facilitate deceptive behaviour in autonomous systems</h4>
      </td>
    </tr>
    <tr>
      <td class="time">15:10</td>
      <td class="session-talk"><span class="paper-title">Using the Fast Downward System in CPCES</span><br /><span class="paper-author">Xiaodi Zhang and Alban Grastien</span></td>
    </tr>
    <tr>
      <td class="time">15:30</td>
      <td class="session-talk"><span class="paper-title">Knowledge Reformulation and Deception as a Defense Against Automated Cyber Adversaries</span><br /><span class="paper-author">Ron Alford, Lukas Chrpa, Mauro Vallati and Andy Applebaum</span></td>
    </tr>
    <tr>
      <td class="time">15:50</td>
      <td class="break">Break</td>
    </tr>
    <tr>
      <td class="time">16:00</td>
      <td class="invited-talk">
        <h4>Keynote: Ehab Al-Shaer. Autonomous Cyber Deception &mdash; Foundations and Practices</h4>
      </td>
    </tr>
    <tr>
      <td class="time">17:00</td>
      <td class="session-talk"><span class="paper-title">Proposing an Architecture to Integrate Stochastic Game and Automated Planning Methods into a Comprehensive Framework: CHIP-GT</span><br /><span class="paper-author">Jane Jean Kiam, Régis Sabbadin and Caroline P.C. Chanel</span></td>
    </tr>
    <tr>
      <td class="time">17:20</td>
      <td class="session-talk"><span class="paper-title">NetStack: A Game Approach to Synthesizing Consistent Network Updates</span><br /><span class="paper-author">Bernhard Clemens Schrenk, Stefan Schmid and Álvaro Torralba</span></td>
    </tr>
    <tr>
      <td class="time">17:40</td>
      <td class="break">Break</td>
    </tr>
    <tr>
      <td class="time">17:50</td>
      <td class="session-talk"><span class="paper-title">Evaluating the robustness of automated driving planners against adversarial influence</span><br /><span class="paper-author">Andres Molina-Markham, Silvia G. Ionescu, Erin Lanus, Derek Ng, Sam Sommerer and Joseph J. Rushanan</span></td>
    </tr>
    <tr>
      <td class="time">18:10</td>
      <td class="session-talk"><span class="paper-title">Plan Critiquing for Assessing Adversarial Effects on Plans</span><br /><span class="paper-author">Ian Kariniemi and Ugur Kuter</span></td>
    </tr>
    <tr>
      <td class="time">18:30</td>
      <td class="session-talk"><span class="paper-title">On the robustness of domain-independent planning engines: the impact of poorly-engineered knowledge</span><br /><span class="paper-author">Mauro Vallati and Lukas Chrpa</span></td>
    </tr>
    <tr>
      <td class="time">18:50</td>
      <td class="opening-remarks">
        <h4>Closing remarks</h4>
      </td>
    </tr>
  </table>

</div>

<h3>Submission Information (historical information)</h3>

<p>
  Authors may submit technical papers of up to 8 pages (+1 for references). We also encourage the submission of short papers (4+1) focussing on preliminary results, and challenge papers (2 pages) to discuss open problems. All submissions should be anonymized and conform to the <a href="https://www.aaai.org/Publications/Templates/AuthorKit22.zip">AAAI style template</a>. The papers must be submitted in a PDF format via the <a href="http://www.easychair.org/conferences/?conf=dapspac2022">EasyChair system</a>. Submissions will be reviewed by at least two referees.
</p>
<p>
  We welcome the presentation of relevant work published recently in archival conferences and journals. For these submissions, please submit a short note pointing to the work and justifying its relevance. If the work is still under review, attach an anonymized copy. Already published work will not be included in the proceedings.
</p>

<h3>Important Dates</h3>

<ul>
  <li><s>Paper submission deadline: April 2nd, 2022 (AOE)</s></li>
  <li><s>Notification: April 30th, 2022</s></li>
  <li>Camera-ready paper submission: June 10th, 2022</li>
</ul>

<h3>Organizing Committee</h3>
<ul>
  <li>Lukas Chrpa, Czech Technical University, Czech Republic</li>
  <li>Mauro Vallati, University of Huddersfield, UK</li>
  <li>Andy Applebaum, Apple, USA</li>
  <li>Ron Alford, The MITRE Corporation, USA</li>
</ul>
<h3>Program Committee</h3>
<ul>
  <li>Mark Wilson, Independent, USA</li>
  <li>Simon Parkinson, University of Huddersfield, UK</li>
  <li>Saad Khan, University of Huddersfield, UK</li>
</ul>
    </section>
  </div>
</div>

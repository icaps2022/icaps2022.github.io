PaperID,Title,Abstract,
HU140,Resolving Misconceptions about the Plans of Agents via Theory of Mind,"For a plan to achieve some goal -- to be valid -- a set of sufficient and necessary conditions must hold. In dynamic settings, agents (including humans) may come to hold false beliefs about these conditions and, by extension, about the validity of their plans or the plans of other agents. Since different agents often believe different things about the world and about the beliefs of other agents, discrepancies may occur between agents' beliefs about the validity of plans. In this work, we explore how agents can use their Theory of Mind to resolve such discrepancies by communicating and/or acting in the environment. We appeal to an epistemic logic framework to allow agents to reason over other agents' nested beliefs, and demonstrate how epistemic planning tools can be used to resolve discrepancies regarding plan validity in a number of domains. Our work shows promise for human decision support as demonstrated by a user study that showcases the ability of our approach to resolve misconceptions held by humans.",Maayan Shvo Toryn Q. Klassen Sheila McIlraith
HU153,Conflict-Based Search for Explainable Multi-Agent Path Finding,"The goal of the Multi-Agent Path Finding (MAPF) problem is to find non-colliding paths for agents in an environment, such that each agent reaches its goal from its initial location. 
In safety-critical applications, a human supervisor may want to verify that the plan is indeed collision-free. To this end, a recent work introduces a notion of explainability for MAPF based on a visualization of the plan as a short sequence of images representing time segments, where in each time segment the trajectories of the agents are disjoint. 
Then, the problem of Explainable MAPF via Segmentation asks for a set of non-colliding paths that admit a short-enough explanation. Explainable MAPF adds a new difficulty to MAPF, in that it is NP-hard with respect to the size of the environment, and not just the number of agents. Thus, traditional MAPF algorithms are not equipped to directly handle Explainable MAPF. In this work, we adapt Conflict Based Search (CBS), a well-studied algorithm for MAPF, to handle Explainable MAPF. We show how to add explainability constraints on top of the standard CBS tree and its underlying A* search. We examine the usefulness of this approach and, in particular, the trade-off between planning time and explainability.",Justin Kottinger Shaull Almagor Morteza Lahijanian
HU192,Explaining Preference-Driven Schedules: The EXPRES Framework,"Scheduling is the task of assigning a set of scarce resources distributed over time to a set of agents, who typically have preferences over the assignments they would like to get.
Due to the constrained nature of these problems, satisfying all agents' preferences often turns infeasible, which might lead to some agents not being happy with the resulting schedule.
Providing explanations has been shown to increase satisfaction and trust in solutions produced by AI tools.
However, explaining schedules poses some particular challenges such as problem interpretability (i.e., generating explanations from a huge and dense amount of information) and privacy preservation (i.e., generating explanations respecting the privacy of other agents involved). 
In this paper we introduce the EXPRES framework, that can explain why a given preference was unsatisfied in a given optimal schedule. The EXPRES framework consists of (i) an explanation generator, that, based on a Mixed-Integer Linear Programming model, finds the best set of reasons that can explain an unsatisfied preference; and (ii) an explanation parser, which translates the generated explanations into human interpretable ones, while preserving agents' privacy.
Through simulations, we show that the explanation generator can efficiently scale to large instances.
Finally, through a set of user studies within J.P. Morgan, we show that employees preferred the explanations generated by EXPRES over human-generated ones when considering workforce scheduling scenarios.",Alberto Pozanco Francesca Mosca Parisa Zehtabi Daniele Magazzeni Sarit Kraus
HU255,Actor-Focused Interactive Visualization for AI Planning,"As we grow more reliant on AI systems for an increasing variety of applications in our lives, the need to understand and interpret such systems also becomes more pronounced, be it for improvement, trust, or legal liability. AI Planning is one type of task that provides explanation challenges, particularly due to the increasing complexity in generated plans and convoluted causal chains that connect actions and determine overall plan structure. While there are many recent techniques to support plan explanation, visual aids for navigating this data are quite limited. Furthermore, there is often a barrier between techniques focused on abstract planning concepts and domain-related explanations. In this paper, we present a visual analytics tool to support plan summarization and interaction, focusing in robotics domains using an actor-based structure. We show how users can quickly grasp vital information about actions involved in a plan and how they relate to each other. Finally, we present a framework used to design our tool, highlighting how general PDDL elements can be converted into visual representations and further connecting concept to domain.",Gabriel Cantareira Gerard Canal Rita Borgo
HU7,Anxiety-Sensitive Planning: From Formal Foundations to Algorithms and Applications,"Anxiety is the most prominent source of stress, harmful behaviours, and psychological disorders. AI systems, usually built for maximizing performance, increase the worldwide exposition to anxiety. This foundational paper introduces Anxiety-Aware Markov Decision Processes (AA-MDPs), the first formalism rooted in fundamental psychology research for modelling the anxiety tied to policies. In addition, this paper formalizes models and practical polynomial algorithms for generating anxiety-sensitive policies. Empirical validation demonstrates that AA-MDPs policies replicate the influence of anxiety on human decision-making observed by fundamental psychology research. Last, this paper demonstrates that AA-MDPs are directly applicable for social good, through a real-world use case (Anxiety-Sensitive Itinerary Planning), the immediate applicability for augmenting any formerly-defined MDP model with anxiety-awareness, and direct tracks developing future high-impact models.",Loïs Vanhée Laurent Jeanpierre Mouaddib Abdel-Illah
HU79,A Network Flow Interpretation of Robust Goal Legibility in Path Finding,"In this paper, we define goal legibility in a multi-agent path-finding setting. We consider a set of identical agents moving in an environment and tasked with reaching a set of locations that need to be serviced. An observer monitors their movements from a distance to identify their destinations as soon as possible. Our algorithm constructs a set of paths for the agents, one to each destination, that overlap as little as possible while satisfying a budget constraint. In this way, the observer, knowing the possible agents' destinations as well as the set of paths they might follow, is guaranteed to determine with certainty an agent's destination by looking at the shortest possible fragment of the agent's trajectory, regardless of when it starts observing. Our technique is robust because the observer's inference mechanism requires no coordination with the agents' motions. By reformulating legible path planning into a classical minimum cost flow problem, we can leverage powerful tools from combinatorial optimization, obtaining fast and scalable algorithms. We present experiments that show the benefits offered by our approach.",Sara Bernardini Fabio Fagnani Santiago Franco Alexandra Neacsu
HU97,VizXP: A Visualization Framework for Conveying Explanations to Users in Model Reconciliation Problems,"Advancements in explanation generation for automated planning algorithms have moved us a step closer towards realizing the full potential of human-AI collaboration in real-world planning applications. Within this context, a framework called model reconciliation has gained a lot of traction, mostly due to its deep connection with a popular theory in human psychology, known as the theory of mind. Existing literature in this setting, however, has mostly been constrained to algorithmic contributions for generating explanations. To the best of our knowledge, there has been very little work on how to effectively convey such explanations to human users, a critical component in human-AI collaboration systems. In this paper, we set out to explore to what extent visualizations are an effective candidate for conveying explanations in a way that can be easily understood. Particularly, by drawing inspiration from work done in visualization systems for classical planning, we propose a visualization framework for visualizing explanations generated from model reconciliation algorithms. We demonstrate the efficacy of our proposed system in a comprehensive user study, where we compare our framework against a text-based baseline for two types of explanations – domain-based and problem-based explanations. Results from the user study show that users, on average, understood explanations better when they are conveyed via our visualization system compared to when they are conveyed via a text-based baseline.",Ashwin Kumar Stylianos Loukas Vasileiou Melanie Bancilhon Alvitta Ottley William Yeoh
HUS127,Evaluating Plan-Property Dependencies: A Web-Based Platform and User Study,"The trade-offs between different desirable plan properties -- e.g.
PDDL temporal plan preferences -- are often difficult to
understand. Recent work addresses this by iterative planning with
explanations elucidating the dependencies between such plan
properties. Users can ask questions of the form ``Why does the plan
not satisfy property p?'', which are answered by ``Because then we
would have to forego q''. It has been shown that such dependencies 
can be computed reasonably efficiently. But is this form of 
explanation actually useful for users? We run a large crowd-worker 
user study (N=100 in each of 3 domains) evaluating that question. To 
enable such a study in the first place, we contribute a Web-based 
platform for iterative planning with explanations, running in standard 
browsers. Comparing users with vs. without access to the explanations,
we find that the explanations enable users to identify better 
trade-offs between the plan properties, indicating an improved 
understanding of the planning task.",Rebecca Eifler Martim Brandao Amanda Coles Jeremy Frank Joerg Hoffmann
IND102,An End-to-End Automatic Cache Replacement Policy Using Deep Reinforcement Learning,"In the past few decades, much research has been conducted on the design of cache replacement policies. Prior work frequently relies on manually-engineered heuristics to capture the most common cache access patterns, or predict the reuse distance and try to identify the blocks that are either cache-friendly or cache-averse. Researchers are now applying recent advances in machine learning to guide cache replacement policy, augmenting or replacing traditional heuristics and data structures. However, most existing approaches depend on the certain environment which restricted their application, e.g, most of the approaches only consider the on-chip cache consisting of program counters (PCs). Moreover, those approaches with attractive hit rates are usually unable to deal with modern irregular workloads, due to the limited feature used. In contrast, we propose a pervasive cache replacement framework to automatically learn the relationship between the probability distribution of different replacement policies and workload distribution by using deep reinforcement learning. We train an end-to-end cache replacement policy only on the past requested address through two simple and stable cache replacement policies. Furthermore, the overall framework can be easily plugged into any scenario that requires cache. Our simulation results on 8 production storage traces run against 3 different cache configurations confirm that the proposed cache replacement policy is effective and outperforms several state-of-the-art approaches.",Yang Zhou Wang Fang Shi Zhan Feng Dan
IND130,Joint Pricing and Matching for City-Scale Ride-Pooling,"Central to efficient ride-pooling are two challenges: (1) how to `price' customers' requests for rides, and (2) if the customer agrees to that price, how to best `match' these requests to drivers. While both of them are interdependent, each challenge's individual complexity has meant that, historically, they have been decoupled and studied individually.

This paper creates a framework for batched pricing and matching in which pricing is seen as a meta-level optimisation over different possible matching decisions. Our key contributions are in developing a variant of the revenue-maximizing auction corresponding to the meta-level optimization problem, and then providing a scalable mechanism for computing posted prices. We test our algorithm on real-world data at city-scale and show that our algorithm reliably matches demand to supply across a range of parameters.",Sanket Shah Meghna Lowalekar Pradeep Varakantham
IND136,Talking Trucks: Decentralized Collaborative Multi-Agent Order Scheduling for Self-Organizing Logistics,"Logistics planning is a complex optimization problem involving multiple decision makers. Automated scheduling systems offer support to human planners; however state-of-the-art approaches often employ a centralized control paradigm. While these approaches have shown great value, their application is hindered in dynamic settings with no central authority. Motivated by real-world scenarios, we present a decentralized approach to collaborative multi-agent scheduling by casting the problem as a Distributed Constraint Optimization Problem (DCOP). Our model-based heuristic approach uses message passing with a novel pruning technique to allow agents to cooperate on mutual agreement, leading to a near-optimal solution while offering low computational costs and flexibility in case of disruptions. Performance is evaluated in three real-world field trials with a logistics carrier and compared against a centralized model-free Deep Q-Network (DQN)-based Reinforcement Learning (RL) approach, a Mixed-Integer Linear Programming (MILP)-based solver, and both human and heuristic baselines. The results demonstrate that it is feasible to have virtual agents make autonomous decisions using our DCOP method, leading to an efficient distributed solution. To facilitate further research in Self-Organizing Logistics (SOL), we provide a novel real-life dataset.",Geert Leonardus Johannes Pingen Christian Rijk van Ommeren Cornelis Jan van Leeuwen Ruben Fransen Tijmen Elfrink Yorick Christiaan de Vries Janarthanan Karunakaran Emir Demirović Neil Yorke-Smith
IND151,Reinforcement Learning Approach to Solve Dynamic Bi-objective Police Patrol Dispatching and Rescheduling Problem,"Police patrol aims to fulfill two main objectives namely to project presence and to respond to incidents in a timely manner. Incidents happen dynamically and can disrupt the initially-planned patrol schedules. The key decisions to be made will be which patrol agent to be dispatched to respond to an incident and subsequently how to adapt the patrol schedules in response to such dynamically-occurring incidents whilst still fulfilling both objectives; which sometimes can be conflicting. In this paper, we define this real-world problem as a Dynamic Bi-Objective Police Patrol Dispatching and Rescheduling Problem and propose a solution approach that combines Deep Reinforcement Learning (specifically neural networks-based Temporal-Difference learning with experience replay) to approximate the value function and a rescheduling heuristic based on ejection chains to learn both dispatching and rescheduling policies jointly. To address the dual objectives, we propose a reward function that implicitly tries to maximize the rate of successfully responding to an incident within a response time target while minimizing the reduction in patrol presence without the need to explicitly set predetermined weights for each objective. The proposed approach is able to compute both dispatching and rescheduling decisions almost instantaneously. Our work serves as the first work in the literature that takes into account these dual patrol objectives and real-world operational consideration where incident response may disrupt existing patrol schedules.",Waldy Joe Hoong Chuin Lau Jonathan Pan
IND170,Stochastic Resource Optimization over Heterogeneous Graph Neural Networks for Failure-Predictive Maintenance Scheduling,"Resource optimization for predictive maintenance is a challenging computational problem that requires inferring and reasoning over stochastic failure models and dynamically allocating repair resources. Predictive maintenance scheduling is typically performed with a combination of ad hoc, hand-crafted heuristics with manual scheduling corrections by human domain experts, which is a labor-intensive process that is hard to scale. In this paper, we develop an innovative heterogeneous graph neural network to automatically learn an end-to-end resource scheduling policy. Our approach is fully graph-based with the addition of state summary and decision value nodes that provides a computationally lightweight and nonparametric means to perform dynamic scheduling. We augment our policy optimization procedure to enable robust learning in highly stochastic environments for which typical actor-critic reinforcement learning methods are ill-suited. In consultation with aerospace industry partners, we develop a virtual predictive-maintenance environment for a heterogeneous fleet of aircraft, called AirME. Our approach sets a new state-of-the-art by outperforming conventional, hand-crafted heuristics and baseline learning methods across problem sizes and various objective functions.",Zheyuan Wang Matthew Gombolay
IND196,Building Resource-Dependent Conditional Plans for an Earth Monitoring Satellite,"This paper introduces a conditional planning and execution system for an Earth monitoring satellite. This system builds plans containing optional acquisitions that are activated or not at execution time depending on the amount of energy actually available. One originality is that the energy activation thresholds computed on the ground take into account the capacity of the satellite to use an heliocentric pointing or switch off the payload when acquisitions are canceled. Another originality is that the conditional planner proposed uses several energy propagation models, from conservative models containing margins on power production to optimistic models that allow opportunistic acquisitions to be planned.",Cédric Pralet David Doose Julien Anxionnat Jérémie Pouly
IND202,Hyper-Heuristics for Personnel Scheduling Domains,"In real-life applications problems can frequently change or require small adaptations. Manually creating and tuning algorithms for different problem domains or different versions of a problem can be cumbersome and time-consuming. In this paper we consider several important problems with high practical relevance, which are Bus Driver Scheduling, Rotating Workforce Scheduling, and Minimum Shift Design. Instead of designing very specific solution methods, we propose to use the more general approach based on hyper-heuristics which take a set of simpler low-level heuristics and combine them to automatically create a fitting heuristic for the problem at hand. This paper presents a major study on applying hyper-heuristics to these domains, which contributes in three different ways: First, it defines new low-level heuristics for these scheduling domains, allowing to apply hyper-heuristics to them for the first time. Second, it provides a comparison of several state-of-the-art hyper-heuristics on those domains. Third, new best solutions for several instances of the different problem domains are found. These results show that hyper-heuristics are able to perform well even on very complex practical problem domains in the area of scheduling and, while being more general and requiring less problem-specific adaptation, can in several cases compete with specialized algorithms for the specific problems. These results help to improve industrial systems in use for solving different scheduling scenarios by allowing faster and easier adaptation to new problem variants.",Lucas Kletzander Nysret Musliu
IND222,OFFICERS: Operational Framework for Intelligent Crime-and-Emergency Response Scheduling,"In the quest to achieve better response times in dense urban environments, law enforcement agencies are seeking AI-driven planning systems to inform their patrol strategies. In this paper, we present a framework, OFFICERS, for deployment planning that learns from historical data to generate deployment schedules on a daily basis. We accurately predict incidents using ST-ResNet, a deep learning technique that captures wide-ranging spatio-temporal dependencies, and solve a large-scale optimization problem to schedule deployment, significantly improving its scalability through a simulated annealing solver. Methodologically, our approach outperforms our previous works where prediction was done using Generative Adversarial Networks, and optimization was performed with the CPLEX solver. Furthermore, we show that our proposed framework is designed to be readily transferable between use cases, handling a wide range of both criminal and non-criminal incidents, with the use of deep learning and a general-purpose efficient solver, reducing dependence on context-specific details. We demonstrate the value of our approach on a police patrol case study, and discuss both the ethical considerations, and operational requirements, for deployment of a lightweight and responsive planning system.",Jonathan Chase Siong Thye Goh Phong Tran Hoong Chuin Lau
IND321,RADAR-X: An Interactive Mixed Initiative Planning Interface Pairing Contrastive Explanations and Revised Plan Suggestions,"Decision support systems seek to enable informed decision-making. In the recent years, automated planning techniques have been leveraged to empower such systems to better aid the human-in-the-loop. The central idea for such decision support systems is to augment the capabilities of the human-in-the-loop with automated planning techniques and enhance the quality of decision-making. In addition to providing planning support, effective decision support systems must be able to provide intuitive explanations based on specific user queries for proposed decisions to its end users. Using this as motivation, we present our decision support system RADAR-X that showcases the ability to engage the user in an interactive explanatory dialogue by first enabling them to specify an alternative to a proposed decision (which we refer to as foils), and then providing contrastive explanations to these user-specified foils which helps the user understand why a specific plan was chosen over the alternative (or foil). Furthermore, the system uses this dialogue to elicit the user's latent preferences and provides revised plan suggestions through three different interaction strategies.",Karthik Valmeekam Sarath Sreedharan Sailik Sengupta Subbarao Kambhampati
IND323,"Analyzing the Efficacy of Flexible Execution, Replanning, and Plan Optimization for a Planetary Lander","Plan execution in unknown environments poses a number of challenges: uncertainty in domain modeling, stochasticity at execution time, and the presence of exogenous events. These challenges motivate an integrated approach to planning and execution that is able to respond intelligently to variation. We examine this problem in the context of the Europa Lander mission concept, and evaluate a planning and execution framework that responds to feedback and task failure using two techniques: flexible execution and replanning with plan optimization. We develop a theoretical framework to estimate gains from these techniques, and we compare these predictions to empirical results generated in simulation. These results indicate that an integrated approach to planning and execution leveraging flexible execution, replanning, and utility maximization shows significant promise for future tightly-constrained space missions that must address significant uncertainty.",Daniel Wang Joseph Russino Connor Basich Steve Chien
IND347,Planning Satellite Swarm Measurements for Earth Science Models: Comparing Constraint Processing and MILP Methods,"We compare two planner solutions for a challenging Earth science application to plan coordinated measurements (observations) for a constellation of satellites. This problem is combinatorially explosive, involving many degrees of freedom for planner choices. Each satellite carries two different sensors and is maneuverable to 61 pointing angle options.  The sensors collect data to update the predictions made by a high-fidelity global soil moisture prediction model. Soil moisture is an important geophysical variable whose knowledge is used in applications such as crop health monitoring and predictions of floods, droughts, and fires.
	The global soil-moisture model produces soil-moisture predictions with associated prediction errors over the globe represented by a grid of 1.67 million Ground Positions (GPs). The prediction error varies over space and time and can change drastically with events like rain/fire. The planner's goal is to select measurements which reduce prediction errors to improve future predictions. This is done by targeting high-quality observations at locations of high prediction-error. Observations can be made in multiple ways, such as by using one or more instruments or different pointing angles; the planner seeks to select the way with the least measurement-error (higher observation quality).
	In this paper we compare two planning approaches to this problem: Dynamic Constraint Processing (DCP) and Mixed Integer Linear Programming (MILP). We match inputs and metrics for both DCP and MILP algorithms to enable a direct apples-to-apples comparison. DCP uses domain heuristics to find solutions within a reasonable time for our application but cannot be proven optimal, while the MILP produces provably optimal solutions. We demonstrate and discuss the trades between DCP flexibility and performance vs. MILP's promise of provable optimality.",Richard Levinson Samantha Niemoeller Sreeja Nag Vinay Ravindra
IND53,Deep Reinforcement Learning for a Multi-Objective Online Order Batching Problem,"On-time delivery and low service costs are two important performance metrics in warehousing operations. This paper proposes a Deep Reinforcement Learning (DRL) based approach to solve the online Order Batching and Sequence Problem (OBSP) to optimize these two objectives. 
To learn how to balance the trade-off between two objectives, we introduce a Bayesian optimization framework to shape the reward function of the DRL agent, such that the influences of learning to these objectives are adjusted to different environments. We compare our approach with several heuristics using problem instances of real-world size where thousands of orders arrive dynamically per hour. 
We show the Proximal Policy Optimization (PPO) algorithm with Bayesian optimization outperforms the heuristics in all tested scenarios on both objectives. In addition, it finds different weights for the components in the reward function in different scenarios, indicating its capability of learning how to set the importance of two objectives under different environments. We also provide policy analysis on the learned DRL agent, where a decision tree is used to infer decision rules to enable the interpretability of the DRL approach.",Martijn Beeks Reza Refaei Afshar Yingqian Zhang Remco Dijkman Claudy van Dorst Stijn de Looijer
MT10,Learning to Estimate Search Progress Using Sequence of States,"Many problems of interest can be solved using heuristic search algorithms. When solving a heuristic search problem, we are often interested in estimating search progress, that is, how much longer until we have a solution. Previous work on search progress estimation derived formulas based on some relevant features that can be observed from the behavior of the search algorithm. In this paper, rather than manually deriving such formulas we leverage machine learning to learn more accurate search progress predictors automatically. We train a Long Short-Term Memory (LSTM) network, which takes as input sequences of nodes expanded by the search algorithm, and predicts how far along with the search we are. Importantly, our approach still treats the search algorithm as a black box and does not look into the contents of search nodes. An empirical evaluation shows our technique outperforms previous search progress estimation techniques.",Matan Sudry Erez Karpas
MT106,Improving Time-Dependent Contraction Hierarchies,"Computing time-optimal shortest paths, in road networks, is one of the most popular applications of Artificial Intelligence. This problem is tricky to solve because road congestion affects travel times. The state-of-the-art in this area is an algorithm called Time-dependent Contraction Hierarchies (TCH). Although fast and optimal, TCH still suffers from two main drawbacks: (1) the usual query process uses bi-directional Dijkstra search to find the shortest path, which can be time-consuming; and (2) the TCH is constructed w.r.t. the entire time domain T, which complicates the search process for queries q that start and finish in a smaller time period Tq ⊂ T. In this work, we improve TCH by making use of time-independent heuristics, which speed up optimal search, and by computing TCHs for different subsets of the time domain, which further reduces the size of the search space. We give a full description of these methods and discuss their optimality-preserving characteristics. We report significant query time improvements against a baseline implementation of TCH.",Bojie Shen Muhammad Aamir Cheema Daniel D. Harabor Peter J. Stuckey
MT113,Debugging a Policy: Automatic Action-Policy Testing in AI Planning,"Testing is a promising way to gain trust in neural action policies π. Previous work on policy testing in sequential decision making targeted environment behavior leading to failure conditions. But if the failure is unavoidable given that behavior, then π is not actually to blame. For a situation to qualify as a ""bug"" in π, there must be an alternative policy π' that does better. We introduce a generic policy testing framework based on that intuition. This raises the bug confirmation problem, deciding whether or not a state is a bug. We analyze the use of optimistic and pessimistic bounds for the design of test oracles approximating that problem. We contribute an implementation of our framework in classical planning, experimenting with several test oracles and with random-walk methods generating test states biased to poor policy performance and/or state novelty. We evaluate these techniques on policies π learned with ASNets. We find that they are able to effectively identify bugs in these π, and that our random-walk biases improve over uninformed baselines.",Marcel Steinmetz Daniel Fišer Hasan Ferit Enişer Patrick Ferber Timo Gros Philippe Heim Daniel Höller Xandra Schuler Valentin Wüstholz Maria Christakis Joerg Hoffmann
MT116,Merge and Shrink Abstractions for Temporal Planning,"Temporal planning is a hard problem that requires good heuristic and memoization strategies to solve efficiently. Merge-and-shrink abstractions have been shown to serve as effective heuristics for classical planning, but they have not yet been applied to temporal planning. Currently, it is still unclear how to implement merge-and-shrink in the temporal domain and how effective the method is in this setting. In this paper we propose a method to compute merge-and-shrink abstractions for temporal planning, applicable to both partial- and total-order temporal planners. The method relies on pre-computing heuristics as formulas of temporal variables that are evaluated at search time, and it allows to use standard shrinking strategies and label reduction. Compared to state-of-the-art Relaxed Planning Graph heuristics, we show that the method leads to improvements in coverage, computation time, and number of explored nodes to solve optimal problems, as well as leading to improvements in unsolvability-proving of problems with deadlines.",Martim Brandao Amanda Coles Andrew Coles Joerg Hoffmann
MT125,Crossword Puzzle Resolution via Monte Carlo Tree Search,"Although the development of AI in games is remarkable, intelligent machines still lag behind humans in games that require the ability of language understanding. In this paper, we focus on the crossword puzzle resolution task. Solving crossword puzzles is a challenging task since it requires the ability to understand natural language and the ability to execute a search over possible answers to find an optimal set of solutions for the grid. Previous solutions are devoted to exploiting heuristic strategies in search to find solutions while having limited ability to explore the search space. We propose a solution for crossword puzzle resolution based on Monte Carlo tree search (MCTS). As far as we know, we are the first to model the crossword puzzle resolution problem as a Markov Decision Process and apply the MCTS to solve it. We construct a dataset for crossword puzzle resolution based on daily puzzles from New York Times with detailed specifications on both the puzzle and clue database selection. Our method can achieve an accuracy of 97% on the dataset.",Lihan Chen Jingping Liu Sihang Jiang Chao Wang Jiaqing Liang Yanghua Xiao Sheng Zhang Rui Song
MT131,On the Complexity of Heuristic Synthesis for Satisficing Classical Planning: Potential Heuristics and Beyond,"Potential functions are a general class of heuristics for classical planning. For satisficing planning, previous work suggested the use of descending and dead-end avoiding (DDA) potential heuristics, which solve planning tasks by backtrack-free search. In this work we study the complexity of devising DDA potential heuristics for classical planning tasks. We show that verifying or synthesizing DDA potential heuristics is PSPACE-complete, but suitable modifications of the DDA properties reduce the complexity of these problems to the first and second level of the polynomial hierarchy. We also discuss the implications of our results for other forms of heuristic synthesis in classical planning.",Malte Helmert Silvan Sievers Alexander Rovner Augusto B. Corrêa
MT139,Pattern Selection Strategies for Pattern Databases in Probabilistic Planning,"Recently, pattern databases have been extended to probabilistic
planning, to derive heuristics for the objectives of goal probability
maximization and expected cost minimization. While this approach
yields both theoretical and practical advantages over techniques
relying on determinization, the problem of selecting the patterns in
the first place has only been scantily addressed as yet, through a
method that systematically enumerates patterns up to a fixed
size. Here we close this gap, extending pattern generation techniques
known from classical planning to the probabilistic case. We consider
hill-climbing as well as counter-example guided abstraction refinement
(CEGAR) approaches, and show how they need to be adapted to obtain
desired properties such as convergence to the perfect value function
in the limit. Our experiments show substantial improvements over
systematic pattern generation and the previous state of the art.",Thorsten Klößner Marcel Steinmetz Álvaro Torralba Joerg Hoffmann
MT148,On Speeding Up Methods for Identifying Redundant Actions in Plans,"Satisficing planning aims at generating plans that are not necessarily optimal. Often, minimising plan generation time negatively affects quality of generated plans. Acquiring plans quickly might be of critical importance in decision-making systems that operate nearly in realtime. However, (very) suboptimal plans might be expensive to execute and more prone to failures. Optimising plans after they are generated, in a spare time, can improve their quality. This paper focuses on speeding up the (Greedy) Action Elimination methods, which are used for identifying and removing redundant actions from plans in polynomial time. We present two enhancements of these methods: Plan Action Landmarks, actions that are not redundant in a given plan, and Action Cycles which are subsequences of actions which if removed do not affect the state trajectory after the last action of the cycle. We evaluate the introduced methods on benchmark problems from the Agile tracks of the International Planning Competition and on plans generated by several state-of-the-art planners, successful in the recent editions of the competition.",Jakub Med Lukas Chrpa
MT154,Task-Guided Inverse Reinforcement Learning under Partial Information,"We study the problem of inverse reinforcement learning (IRL), where the learning agent recovers a reward function using expert demonstrations. Most of the existing IRL techniques make the often unrealistic assumption that the agent has access to full information about the environment. We remove this assumption by developing an algorithm for IRL in partially observable Markov decision processes (POMDPs). The algorithm addresses several limitations of existing techniques that do not take the information asymmetry between the expert and the learner into account. First, it adopts causal entropy as the measure of the likelihood of the expert demonstrations as opposed to entropy in most existing IRL techniques, and avoids a common source of algorithmic complexity. Second, it incorporates task specifications expressed in temporal logic into IRL. Such specifications may be interpreted as side information available to the learner a priori in addition to the demonstrations and may reduce the information asymmetry. Nevertheless, the resulting formulation is still nonconvex due to the intrinsic nonconvexity of the so-called forward problem, i.e., computing an optimal policy given a reward function, in POMDPs. We address this nonconvexity through sequential convex programming and introduce several extensions to solve the forward problem in a scalable manner.
This scalability allows computing policies that incorporate memory at the expense of added computational cost yet also outperform memoryless policies. We demonstrate that, even with severely limited data, the algorithm learns reward functions and policies that satisfy the task and induce a similar behavior to the expert by leveraging the side information and incorporating memory into the policy.",Franck Djeumou Murat Cubuktepe Craig Lennon Ufuk Topcu
MT164,Solving Job-Shop Scheduling Problems with QUBO-Based Specialized Hardware,"The emergence of specialized hardware, such as quantum computers and Digital/CMOS annealers, and the slowing of performance growth of general-purpose hardware raises an important question for our community: how can the high-performance, specialized solvers be used for planning and scheduling problems? In this work, we focus on the job-shop scheduling problem (JSP) and Quadratic Unconstrained Binary Optimization (QUBO) models, the mathematical formulation shared by a number of novel hardware platforms. We study two direct QUBO models of JSP and propose a novel large neighborhood search (LNS) approach, that hybridizes a QUBO model with constraint programming (CP). Empirical results show that our LNS approach significantly outperforms classical CP-based LNS methods and a mixed integer programming model, while being competitive with CP for large problem instances. This work is the first approach that we are aware of that can solve non-trivial JSPs using QUBO hardware, albeit as part of a hybrid algorithm.",Jiachen Zhang Giovanni Lo Bianco Chris Beck
MT17,Conflict-Directed Diverse Planning for Logic-Geometric Programming,"Robots operating in the real world must combine task planning for reasoning about what to do with motion planning for reasoning about how to do it -- this is known as task and motion planning.  One promising approach for task and motion planning is Logic Geometric Programming (LGP) which integrates a logical layer and a geometric layer in an optimization formulation. The logical layer describes feasible high-level actions at an abstract symbolic level, while the geometric layer uses continuous optimization methods to reason about motion trajectories with geometric constraints. 
In this paper we propose a new approach for solving task and motion planning problems in the LGP formulation, that leverages state-of-the-art diverse planning at the logical layer to explore the space of feasible logical plans, and minimizes the number of optimization problems to be solved on the continuous geometric layer. To this end, geometric infeasibility is fed back into planning by identifying prefix conflicts and incorporating this back into the planner through a novel multi-prefix forbidding compilation. We further leverage diverse planning with a new novelty criteria for selecting candidate plans based on the prefix novelty, and a metareasoning approach which attempts to extract only useful conflicts by leveraging the information that is gathered in the course of solving the given problem.",Joaquim Ortiz de Haro Erez Karpas Marc Toussaint Michael Katz
MT180,Admissible Heuristics for Multi-Objective Planning,"Planning problems of practical relevance commonly include multiple objectives that are difficult to weight a priori. Several heuristic search algorithms computing the Pareto front of non-dominated solutions have been proposed to handle these multi-objective (MO) planning problems. However, the design of informative admissible heuristics to guide these algorithms has not received the same level of attention. The standard practice is to use the so-called ideal point combination, which applies a single-objective heuristic to each objective independently, without capturing any of the trade-offs between them. This paper fills this gap: we extend several classes of classical planning heuristics to the multi-objective case, in such a way as to reflect the tradeoffs underlying the various objectives. We find that MO abstraction heuristics achieve overall the best performance, but that not every MO generalisation pays off.",Florian Geißer Patrik Haslum Sylvie Thiebaux Felipe Trevizan
MT184,Beyond Stars – Generalized Topologies for Decoupled Search,"Decoupled search decomposes a classical planning task by partitioning its variables such that the dependencies between the resulting factors form a star topology. In this topology, a single center factor can interact arbitrarily with a set of leaf factors. The leaves, however, can interact with each other only indirectly via the center. In this work, we generalize this structural requirement and allow arbitrary topologies. The components must not overlap, i.e., each state variable is assigned to exactly one factor, but the interaction between factors is not restricted. We show how this generalization is connected to star topologies, which implies the correctness of decoupled search with this novel type of decomposition. We introduce factoring methods that automatically identify these topologies on a given planning task. Empirically, the generalized factorings lead to increased applicability of decoupled search on standard IPC benchmarks, as well as to superior performance compared to known factoring methods.",Daniel Gnad Álvaro Torralba Daniel Fišer
MT187,Flexible FOND HTN Planning: A Complexity Analysis,"Hierarchical Task Network (HTN) planning is an expressive planning formalism that has often been advocated to address real-world problems. Yet few extensions exist that can deal with the many challenges encountered in the real world, one being the capability to express uncertainty. Recently, a new HTN formalism for fully observable nondeterministic problems was proposed and studied theoretically. In this paper, we lay out limitations of that formalism and propose an alternative definition, which addresses and resolves such limitations. We also study its complexity for certain problems.",Dillon Chen Pascal Bercher
MT195,Efficient Computation and Informative Estimation of h+ by Integer and Linear Programming,"We investigate modeling cost optimal delete-free STRIPS Planning by Integer/Linear Programming (IP/LP). We introduce two IP models and their LP relaxations based on a recently formulated representation of relaxed plans, named causal relaxed plan representation. The new models are produced by enforcing acyclicity in so-called causal relation graphs using vertex elimination and time labeling methods. We empirically show that while the vertex elimination based method outperforms the time labeling based method and all previously introduced domain independent methods for computing the exact values of h+, the time labeling based LP model is faster to solve compared to its vertex elimination based alternative, making it more suitable for using as heuristic function for optimal planning. We also theoretically analyze the admissible heuristic functions obtained by solving our LP models, and prove that the vertex elimination based heuristic is at least as informative as the time labeling based heuristic. Moreover, our empirical analysis shows that our vertex elimination based heuristic, which is a novel admissible estimation of h+, often has information complementary to that of the LM-cut heuristic.",Masood Feyzbakhsh Rankooh Jussi Rintanen
MT2,Generalized Linear Integer Numeric Planning,"Classical planning aims to find a sequence of actions that guarantees goal achievement from an initial state. The representative framework of classical planning is based on propositional logic. Due to the weak expressiveness of propositional logic, many applications of interest cannot be formalized as a classical planning problem. Some extensions such as numeric planning and generalized planning (GP) are therefore proposed. Qualitative numeric planning (QNP) is a decidable class of numeric and generalized extensions and serves as a numeric abstraction of GP. However, QNP is still far from being perfect and needs further improvement. In this paper, we introduce another generalized version of numeric planning, namely generalized linear integer numeric planning(GLINP), which is a more suitable abstract framework of GP than QNP. In addition, we develop a general framework to synthesize solutions to GLINP problems. Finally, we evaluate our approach on a number of benchmarks, and experimental results justify the effectiveness and scalability of our proposed approach.",Xiaoyou Lin Qingliang Chen Liangda Fang Quanlong Guan Weiqi Luo Kaile Su
MT200,A Hybrid Genetic Algorithm for the Vehicle Routing Problem with Roaming Delivery Locations,"The Vehicle Routing Problem with Roaming Delivery Locations (VRPRDL) is a variant of the Vehicle Routing Problem (VRP) in which a customer can be present at many locations during a working day and a time window is associated with each location. The objective is to find a set of routes such that (i) the total traveling cost is minimized, (ii) only one location of each customer is visited within its time window, and (iii) all capacity constraints are satisfied. To solve the problem, we introduce a hybrid genetic algorithm which relies on problem-tailored solution representation, mutation, local search operators, as well as a set covering component exploring routes found during the search to find better solutions. We also propose a new split procedure which based on dynamic programming to evaluate the fitness of chromosomes. Experiments conducted on the benchmark instances clearly show that our proposed algorithm outperforms existing approaches in terms of stability and solution quality. We also improve 49 best known solutions of the literature.",Quang Anh Pham Minh Hoàng Hà Duy Manh Vu Huy Hoang Nguyen
MT201,Operator-Potentials in Symbolic Search: From Forward to Bi-directional Search,"Symbolic search using binary decision diagrams is a state-of-the-art technique for cost-optimal planning. Heuristic search in this context has been problematic as even a very informative heuristic can be detrimental in case it induces difficult-to-represent state partitionings. It was recently shown that operator-potential heuristics can address this issue in forward search by computing a numeric potential for each operator corresponding to the change of the heuristic value induced by that operator.

Forward search is, however, not the best known variant of symbolic search. Here we investigate the integration with backward and bi-directional search instead. We prove that forward search (distance-to-goal) operator-potential heuristics can be turned into backward search (distance-to-initial-state) heuristics elegantly in this context, by summing the backward search path operator-potentials with the initial state goal-distance estimate. We run exhaustive experiments on IPC benchmarks, showing that significant performance improvements can be obtained over symbolic forward search and other state-of-the-art techniques.",Daniel Fišer Álvaro Torralba Joerg Hoffmann
MT208,Detecting Unsolvability Based on Separating Functions,"While the unsolvability IPC sparked a multitude of planners proficient in detecting unsolvable planning tasks, there are gaps where concise unsolvability arguments are known but no existing planner can capture them without prohibitive computational effort. One such example is the sliding tiles puzzle, where solvability can be decided in polynomial time with a parity argument. We introduce separating functions, which can prove that one state is unreachable from another, and show under what conditions a potential function over any nonzero ring is a separating function. We prove that we can compactly encode these conditions for potential functions over features that are pairs, and show in which cases we can efficiently synthesize functions satisfying these conditions. We experimentally evaluate a domain-independent algorithm that successfully synthesizes such separating functions from PDDL representations of the sliding tiles puzzle, the Lights Out puzzle, and Peg Solitaire.",Remo Christen Salomé Eriksson Florian Pommerening Malte Helmert
MT221,LM-Cut Heuristics for Optimal Linear Numeric Planning,"While numeric variables play an important, sometimes central, role in many planning problems arising from real world scenarios, most of the currently available heuristic search planners either do not support such variables or impose heavy restrictions on them. In particular, most admissible heuristics are restricted to domains where actions can only change numeric variables by predetermined constants. In this work, we consider the setting of optimal numeric planning with linear effects, where actions can have numeric effects that assign the result of the evaluation of a linear formula. We extend a recent formulation of Numeric LM-cut for simple effects by adding conditional effects and second-order simple effects, allowing the heuristic to produce admissible estimates for tasks with linear numeric effects. Empirical comparison shows that the proposed LM-cut heuristics favorably compete with the currently available state-of-the-art heuristics and achieve significant improvement in coverage in the domains with second-order simple effects.",Ryo Kuroiwa Alexander Shleyfman Chris Beck
MT228,Biased Exploration for Satisficing Heuristic Search,"Satisficing heuristic search such as greedy best-first search (GBFS) suffers from local minima, regions where heuristic values are inaccurate and a good node has a worse heuristic value than other nodes. Search algorithms that incorporate exploration mechanisms in GBFS empirically reduce the search effort to solve difficult problems. Although some of these methods entirely ignore the guidance of a heuristic during their exploration phase, intuitively, a good heuristic should have some bound on its inaccuracy, and exploration mechanisms should exploit this bound. In this paper, we theoretically analyze what a good node is for satisficing heuristic search algorithms and show that the heuristic value of a good node has an upper bound if a heuristic satisfies a certain property. Then, we propose biased exploration mechanisms which select lower heuristic values with higher probabilities. In the experiments using synthetic graph search problems and classical planning benchmarks, we show that the biased exploration mechanisms can be useful. In particular, one of our methods, Softmin-Type(h), significantly outperforms other GBFS variants in classical planning and improves the performance of Type-LAMA, a state-of-the-art classical planner.",Ryo Kuroiwa Chris Beck
MT233,An Exact Algorithm for the Linear Tape Scheduling Problem,"Magnetic tapes are often considered as an outdated storage
technology, yet they are still used to store huge amounts of
data. Their main interests are a large capacity and a low price
per gigabyte, which come at the cost of a much larger file access time than on disks. With tapes, finding the right ordering
of multiple file accesses is thus key to performance. Moving
the reading head back and forth along a kilometer long tape
has a non-negligible cost and unnecessary movements thus
have to be avoided. However, the optimization of tape request
ordering has rarely been studied in the scheduling literature,
much less than I/O scheduling on disks. For instance, minimizing 
the average service time for several read requests on a
linear tape remains an open question.

Therefore, in this paper, we aim at improving the quality of
service experienced by users of tape storage systems, and not
only the peak performance of such systems. To this end, we
propose a reasonable polynomial-time exact algorithm while
this problem and simpler variants have been conjectured NP-hard. We also refine the proposed model by considering U-turn penalty costs accounting for inherent mechanical accelerations. Then, we propose a low-cost variant of our optimal
algorithm by restricting the solution space, yet still yielding
an accurate suboptimal solution. Finally, we compare our algorithms to existing solutions from the literature on logs of
the mass storage management system of a major datacenter.
This allows us to assess the quality of previous solutions and
the improvement achieved by our low-cost algorithm. Aiming
for reproducibility, we make available the complete implementation of the algorithms used in our evaluation, alongside
the dataset of tape requests that is, to the best of our knowledge, the first of its kind to be publicly released.",Valentin Honoré Bertrand Simon Frédéric Suter
MT240,Cost Partitioning Heuristics for Stochastic Shortest Path Problems,"In classical planning, cost partitioning is a powerful method which allows to combine multiple admissible heuristics while retaining an admissible bound. In this paper, we extend the theory of cost partitioning to probabilistic planning by generalizing from deterministic transition systems to stochastic shortest path problems (SSPs). We show that fundamental results related to cost partitioning still hold in our extended theory. We also investigate how to optimally partition costs for a large class of abstraction heuristics for SSPs. Lastly, we analyze occupation measure heuristics for SSPs as well as the theory of approximate linear programming for reward-oriented Markov decision processes. All of these fit our framework and can be seen as cost-partitioned heuristics.",Thorsten Klößner Florian Pommerening Thomas Keller Gabriele Röger
MT257,Learning Sketches for Decomposing Planning Problems into Subproblems of Bounded Width,"Recently, sketches have been introduced as a general language for representing the subgoal structure of instances drawn from the same domain. Sketches are collections of rules of the form C -> E over a given set of features where C expresses Boolean conditions and E expresses qualitative changes. Each sketch rule defines a subproblem: going from a state that satisfies C to a state that achieves the change expressed by E or a goal state. Sketches can encode simple goal serializations, general policies, or decompositions of bounded width that can be solved greedily, in polynomial time, by the SIW_R variant of the SIW algorithm. Previous work has shown the computational value of sketches over  benchmark domains that, while tractable, are challenging for domain-independent planners. In this work, we address the problem of learning sketches automatically given a planning domain, some instances of the target class of problems, and the desired bound on the sketch width. We present a logical formulation of the problem, an implementation using the ASP solver Clingo, and experimental results. The sketch learner and the SIW_R planner yield a domain-independent planner that learns and exploits domain structure in a crisp and explicit form.",Dominik Drexler Jendrik Seipp Hector Geffner
MT262,Iterative Depth-First Search for FOND Planning,"Fully Observable Non-Deterministic (FOND) planning models uncertainty through actions with non-deterministic effects. Existing FOND planning algorithms are effective and employ a wide range of techniques. However, most of the existing algorithms are not robust for dealing with both non-determinism and task size. In this paper, we develop a novel iterative depth-first search algorithm that solves FOND planning tasks and produces strong cyclic policies. Our algorithm is explicitly designed for FOND planning, addressing more directly the non-deterministic aspect of FOND planning, and it also exploits the benefits of heuristic functions to make the algorithm more effective during the iterative searching process. We compare our proposed algorithm to well-known FOND planners, and show that it has robust performance over several distinct types of FOND domains considering different metrics.",Ramon Fraga Pereira André Grahl Pereira Frederico Messa Giuseppe De Giacomo
MT278,The Power of Reformulation: From Validation to Planning in PDDL+,"PDDL+ allows the formal specification of systems representing mixed discrete-continuous representation, under both discrete and continuous dynamics; this expressiveness is pivotal in real-world applications. An important aspect is the capability of validating plans obtained by planning systems, and assessing their compliance against the domain's model. Unfortunately, a very limited number of validation tools are capable of dealing with PDDL+ tasks. To overcome this problem, in this work we propose an approach that allows exploiting any domain-independent PDDL+ or PDDL2.1 planning engine for validating PDDL+ plans. We introduce a set of translations that, given a PDDL+ plan and the corresponding PDDL+ task, generate a new PDDL+ or PDDL2.1 whose solvability is bound to the validity of the considered plan. We empirically evaluate the usefulness of the proposed approach on a range of PDDL+ benchmarks under an interpretation of time that can be either continuous (through a PDDL+ translation) or discrete (through a PDDL+ or a PDDL2.1 translation).",Francesco Percassi Enrico Scala Mauro Vallati
MT303,Lazy Rearrangement Planning in Confined Spaces,"Object rearrangement is important for many applications but remains challenging, especially in confined spaces, such as shelves, where objects cannot be accessed from above and they block reachability to each other. Such constraints require many motion planning and collision checking calls, which are computationally expensive. In addition, the arrangement space grows exponentially with the number of objects. To address these issues, this work introduces a lazy evaluation framework with a local monotone solver and a global planner. Monotone instances are those that can be solved by moving each object at most once. A key insight is that reachability constraints at the grasps for objects' starts and goals can quickly reveal dependencies between objects without having to execute expensive motion planning queries. Given that, the local solver builds lazily a search tree that respects these reachability constraints without verifying that the arm paths are collision free. It only collision checks when a promising solution is found. If a monotone solution is not found, the non-monotone planner loads the lazy search tree and explores ways to move objects to intermediate locations from where monotone solutions to the goal can be found. Results show that the proposed framework can solve difficult instances in confined spaces with up to 16 objects, which state-of-the-art methods fail to solve. It also solves problems faster than alternatives, when the alternatives find a solution. It also achieves high-quality solutions, i.e., only 1.8 additional actions on average are needed for non-monotone instances.",Rui Wang Kai Gao Jingjin Yu Kostas Bekris
MT308,Conflict-Based Search for the Virtual Network Embedding Problem,"In emerging network virtualization architectures, service providers will be able to create many heterogeneous virtual networks and offer customized end-to-end services by leasing shared resources from infrastructure providers. The Virtual Network Embedding (VNE) problem is central to such technology. It involves the proper allocation of CPU and bandwidth resources available in a physical substrate network to meet the demands of multiple virtual networks. Combinatorially, the VNE problem is a problem in resource management that is NP-hard to solve. In this paper, we present a novel version of the Conflict-Based Search (CBS) algorithm for solving the VNE problem. Our approach, called VNE-CBS, is inspired by the success of the CBS framework in the Multi-Agent Path Finding domain. We successfully address the unique challenges in applying the CBS framework to the VNE problem, and, in doing so, we pave the way for overcoming a crucial issue in Internet ossification via heuristic search methods. On the theoretical front, we show that, unlike many existing algorithms, our algorithm is complete and optimal. On the experimental front, we show that our algorithm significantly outperforms other state-of-the-art methods on various benchmark instances for both the offline and online versions of the VNE problem.",Yi Zheng Srivatsan Ravi Erik Kline Sven Koenig T. K. Satish Kumar
MT324,Euclidean Distance-Optimal Post-processing of Grid-Based Paths,"Paths planned over grids can often be suboptimal in an Euclidean space and contain a large number of unnecessary turns. Consequently, researchers have looked into post-processing techniques to improve the paths after they are planned. In this paper, we propose a novel post-processing technique, called Homotopic Visibility Graph Planning (HVG) which differentiates itself from existing post-processing methods in that it is guaranteed to shorten the path such that it is at least as short as the provably shortest path that lies within the same topological class as the initially computed path. We propose the algorithm, provide proofs and compare it experimentally against other post-processing methods and any-angle planning algorithms.",Guru Koushik Senthil Kumar Sandip Aine Maxim Likhachev
MT328,A*pex: Efficient Approximate Multi-Objective Search on Graphs,"In multi-objective search, edges are annotated with cost vectors consisting of multiple cost components. A path dominates another path with the same start and goal vertices iff the component-wise sum of the cost vectors of the edges of the former path is ``less than'' the component-wise sum of the cost vectors of the edges of the latter path. The Pareto-optimal solution set is the set of all undominated paths from a given start vertex to a given goal vertex. Its size can be exponential in the size of the graph being searched, which makes multi-objective search time-consuming. In this paper, we therefore study how to find an approximate Pareto-optimal solution set for a user-provided vector of approximation factors. The size of such a solution set can be significantly smaller than the size of the Pareto-optimal solution set, which enables the design of approximate multi-objective search algorithms that are efficient and produce small solution sets. We present such an algorithm in this paper which we call A*pex and which builds on PP-A*, a state-of-the-art approximate bi-objective search algorithm (where there are only two cost components) but (1) makes PP-A* more efficient for bi-objective search and (2) generalizes it to multi-objective search for any number of cost components. We first analyze the correctness of A*pex and then experimentally demonstrate its efficiency advantage over existing approximate algorithms for bi- and tri-objective search.",Han Zhang Oren Salzman T. K. Satish Kumar Ariel Felner Carlos Hernández Ulloa Sven Koenig
MT35,Simple Temporal Networks for Improvisational Teamwork,"When communication between teammates is limited to observations of each other's actions, agents may need to improvise to stay coordinated. Unfortunately, current methods inadequately capture the uncertainty introduced by a lack of direct communication. This paper augments existing frameworks to introduce Simple Temporal Networks for Improvisational Teamwork (STN-IT)—a formulation that captures both the temporal dependencies and uncertainties between agents who need to coordinate but lack reliable communication. We define the notion of strong controllability for STN-ITs, which establishes a static scheduling strategy for controllable agents that produces a consistent team schedule, as long as non-communicative teammates act within known problem constraints. We provide both an exact and approximate approach for finding strongly controllable schedules, empirically demonstrate the trade-offs between these approaches on benchmarks of STN-ITs, and show analytically that the exact method is correct.",Malia Morgan Julianna Schalkwyk Huaxiaoyue Wang Hannah Davalos Ryan Martinez Vibha Rohilla James Boerkoel
MT38,Solving Simultaneous Target Assignment and Path Planning Efficiently with Time-Independent Execution,"Real-time planning for a combined problem of target assignment and path planning for multiple agents, also known as the unlabeled version of Multi-Agent Path Finding (MAPF), is crucial for high-level coordination in multi-agent systems, e.g., pattern formation by robot swarms. This paper studies two aspects of unlabeled-MAPF: (1) offline scenario: solving large instances by centralized approaches with small computation time, and (2) online scenario: executing unlabeled-MAPF despite timing uncertainties of real robots. For this purpose, we propose TSWAP, a novel sub-optimal complete algorithm, which takes an arbitrary initial target assignment then repeats one-timestep path planning with target swapping. TSWAP can adapt to both offline and online scenarios. We empirically demonstrate that Offline TSWAP is highly scalable; providing near-optimal solutions while reducing runtime by orders of magnitude compared to existing approaches. In addition, we present the benefits of Online TSWAP, such as delay tolerance, through real-robot demos.",Keisuke Okumura Xavier Defago
MT44,Neural Network Action Policy Verification via Predicate Abstraction,"Neural networks (NN) are an increasingly important representation of action policies. Verifying that such policies are safe is potentially very hard as it compounds the state space explosion with the difficulty of analyzing even single NN decision episodes. Here we address that challenge through abstract reachability analysis. We show how to compute predicate abstractions of the policy state space subgraph induced by fixing an NN action policy. A key sub-problem here is the computation of abstract state transitions that may be taken by the policy, which as we show can be tackled by connecting to off-the-shelf SMT solvers. We devise a range of algorithmic enhancements, leveraging relaxed tests to avoid costly calls to SMT. We empirically evaluate the resulting machinery on a collection of benchmarks. The results show that our enhancements are required for practicality, and that our approach can outperform two competing approaches based on explicit enumeration and bounded-length verification.",Marcel Vinzent Marcel Steinmetz Joerg Hoffmann
MT49,On the Expressive Power of Planning Formalisms in Conjunction with LTL,"Linear Temporal Logic (LTL) has been widely employed in various planning formalisms, e.g., in the STRIPS formalism, in order to specify constraints over state trajectories in a planning problem. In this paper, we investigate the expressive power of two planning formalisms in conjunction with LTL that are most commonly seen in non-hierarchical planning and hierarchical planning respectively, namely the STRIPS formalism and the Hierarchical Task Network (HTN) formalism. We do so by interpreting the set of all solutions to a planning problem as a formal language and comparing it with other formal ones, e.g., star-free languages. Our results provide an in-depth insight into the theoretical properties of the investigated planning formalisms and henceforth explore the common structure shared by solutions to planning problems in certain planning formalisms.",Songtuan Lin Pascal Bercher
MT54,Beam Search: Faster and Monotonic,"Beam search is a popular satisficing approach to heuristic search problems that allows one to trade increased computation time for lower solution cost by increasing the beam width parameter.  We make two contributions to the study of beam search.  First, we show how to make beam search monotonic; that is, we provide a new variant that guarantees nonincreasing solution cost as the beam width is increased.  This makes setting the beam parameter much easier.  Second, we show how using distance-to-go estimates can allow beam search to find better solutions more quickly in domains with non-uniform costs.  Together, these results improve the practical effectiveness of beam search.",Sofia Lemons Carlos Linares Robert Holte Wheeler Ruml
MT55,Encoding Lifted Classical Planning in Propositional Logic,"Planning models are usually defined in lifted, i.e. first order formalisms, while most solvers need (variable-free) grounded representations. Though techniques for grounding prune unnecessary parts of the model, grounding might – nevertheless – be prohibitively expensive in terms of runtime. To overcome this issue, there has been renewed interest in solving planning problems based on the lifted representation in the last years. While these approaches are based on (heuristic) search, we present an encoding of lifted classical planning in propositional logic and use SAT solvers to solve it. Our evaluation shows that our approach is competitive with the heuristic search-based approaches in satisficing planning and outperforms them in a (length-)optimal setting.",Daniel Höller Gregor Behnke
MT62,Planning for Risk-Aversion and Expected Value in MDPs,"Planning in Markov decision processes (MDPs) typically optimises the expected cost. However, optimising the expectation does not consider the risk that for any given run of the MDP, the total cost received may be unacceptably high. An alternative approach is to find a policy which optimises a riskaverse objective such as conditional value at risk (CVaR). However, optimising the CVaR alone may result in poor performance in expectation. In this work, we begin by showing that there can be multiple policies which obtain the optimal CVaR. This motivates us to propose a lexicographic approach which minimises the expected cost subject to the constraint that the CVaR of the total cost is optimal. We present an algorithm for this problem and evaluate our approach on four domains. Our results demonstrate that our lexicographic approach improves the expected cost compared to the state of the art algorithm, while achieving the optimal CVaR.",Marc Rigter Paul Duckworth Bruno Lacerda Nick Hawes
MT64,Classical Planning as QBF without Grounding,"Most classical planners use grounding as a preprocessing step, essentially reducing planning to propositional logic. However, grounding involves instantiating all rules and actions with concrete object combinations, and results in large encodings for SAT/QBF-based planners.
This severe cost in memory becomes a main bottleneck when actions have many parameters, such as in the Organic Synthesis problems from the IPC 2018 competition.
We provide a compact QBF encoding that is logarithmic in the number of objects and avoids grounding completely by using universal quantification for object combinations.
We show that we can solve some of the Organic Synthesis problems, which could not be handled before by any SAT/QBF based planners due to grounding.",Irfansha Shaik Jaco van de Pol
MT77,Uniform Machine Scheduling with Predictions,"The revival in learning theory has provided us with improved capabilities for accurate predictions. This work contributes to an emerging research agenda of online scheduling with predictions by studying the makespan minimization in uniformly related machine non-clairvoyant scheduling with job size predictions. Our task is to design online algorithms that effectively use predictions and have performance guarantees with varying prediction quality. We first propose a simple algorithm-independent prediction error measurement to quantify prediction quality. To effectively use the predicted job sizes, we design an offline improved 2-relaxed decision procedure approximating the optimal schedule. With this decision procedure, we propose an online O(min{log eta, log m})-competitive algorithm that assumes a known prediction error. Finally, we extend this algorithm to construct a robust O(min{log eta, log m})-competitive algorithm that does not assume a known error. Both algorithms require only moderate predictions to improve the well-known Omega(log m) lower bound, showing the potential of using predictions in managing uncertainty.",Tianming Zhao Wei Li Albert Zomaya
MT78,Optimal Mixed Strategies for Cost-Adversarial Planning Games,"This paper shows that domain-independent tools from classical planning can be used to model and solve a broad class of game-theoretic problems we call Cost-Adversarial Planning Games (CAPGs). We define CAPGs as 2-player normal-form games specified by a planning task and a finite collection of cost functions. The first player (a planning agent) strives to solve a planning task optimally but has limited knowledge about its action costs. The second player (an adversary agent) controls the actual action costs. Even though CAPGs need not be zero-sum, every CAPG has an associated zero-sum game whose Nash equilibrium provides the optimal randomized strategy for the planning agent in the original CAPG. We show how to find the Nash equilibrium of the associated zero-sum game using a cost-optimal planner via the Double Oracle algorithm. To demonstrate the expressivity of CAPGs, we formalize a patrolling security game and several IPC domains as CAPGs.",Rostislav Horčík Álvaro Torralba Pavel Rytíř Lukas Chrpa Stefan Edelkamp
MT96,It Costs to Get Costs! A Heuristic-Based Scalable Goal Assignment Algorithm for Multi-Robot Systems,"The goal assignment problem for a multi-robot application involves assigning a unique goal to each robot to minimize the total cost of movement for all the robots. A significant step in the state-of-the-art algorithms solving this problem is to find the cost associated with each robot-goal pair. For a large multi-robot system with many robots and many goals in a complex workspace, the computation time required to find the paths for all robot-goal pairs may become prohibitively large. We present an algorithm that solves the optimal goal assignment problem without computing the paths between all the robot-goal pairs. Instead, our algorithm computes the obstacle-free optimal path for any robot-goal pair in a demand-driven way, i.e., if it is absolutely required to ensure the optimality of the goal assignment. We evaluate our algorithm extensively on both randomly generated and standard workspaces for hundreds of robots. Our experimental results demonstrate that the proposed algorithm achieves an order-of-magnitude speedup over the state-of-the-art baseline algorithm. To the best of our knowledge, our algorithm is the first one to solve the multi-robot optimal goal assignment problem without computing the paths for all robot-goal pairs explicitly, guaranteeing high scalability.",Aakash Aakash Indranil Saha
MTS1,A Compilation Based Approach to Finding Centroids and Minimum Covering States in Planning,"In some scenarios, an agent may want to prepare for achieving one of several possible goals, by reaching some state which is close (according to some metric) to all possible goals. Recently, this task was formulated as finding centroids (which minimize the average distance to the goals) or minimum covering states (which minimize the maximum distance). In this paper, we present a compilation based approach for finding such states. Our compilation is very similar to the one used to find the worst case distinctiveness (wcd) in goal recognition design (GRD), and is orders of magnitude faster than the previous state-of-the-art, which was based on exhaustive search.",Erez Karpas
MTS128,Best-First Width Search for Lifted Classical Planning,"Lifted planners are useful to solve tasks that are too hard to ground. Still, computing informative lifted heuristics is difficult: directly adapting ground heuristics to the lifted setting is often too expensive, and extracting heuristics from the lifted representation can be uninformative. A natural alternative for lifted planners is to use width-based search. These algorithms are among the strongest for ground planning, even the variants that do not access the action model. In this work, we adapt best-first width search to the lifted setting and show that this yields state-of-the-art performance for hard-to-ground planning tasks.",Augusto B. Corrêa Jendrik Seipp
MTS15,Compiling HTN Plan Verification Problems into HTN Planning Problems,"Plan Verification is the task of deciding whether a sequence of actions is a solution for a given planning problem. In HTN planning, the task is computationally expensive and may be up to NP-hard. However, there are situations where it needs to be solved, e.g. when a solution is post-processed, in systems using approximation, or just to validate whether a planning system works correctly (e.g. for debugging or in a competition). There are verification systems based on translations to propositional logic and on techniques from parsing. Here we present a third approach and translate HTN plan verification problems into HTN planning problems. These can be solved using any HTN planning system. We collected a new benchmark set based on models and results of the 2020 International Planning Competition. Our evaluation shows that our compilation outperforms the approaches from the literature.",Daniel Höller Julia Wichlacz Pascal Bercher Gregor Behnke
MTS162,Multi-Agent Path Finding with Temporal Jump Point Search,"Temporal Jump Point Search (JPST) is a recently introduced algorithm for grid-optimal pathfinding among dynamic temporal obstacles.  In this work we consider JPST as a low-level planner in Multi-Agent  Path Finding (MAPF).  We investigate how the canonical ordering of JPST  can negatively impact MAPF performance and we consider several strategies which allow us to overcome these limitations. Experiments show our new CBS/JPST approach can substantially improve on CBS/SIPP,  a contemporary and leading method from the area.",Shuli Hu Daniel Harabor Graeme Gange Peter J. Stuckey Nathan Sturtevant
MTS225,New Refinement Strategies for Cartesian Abstractions,"Cartesian counterexample-guided abstraction refinement (CEGAR) yields strong heuristics for optimal classical planning. CEGAR repeatedly finds counterexamples, i.e., abstract plans that fail for the concrete task. Although there are usually many such abstract plans to choose from, the refinement strategy from previous work is to choose an arbitrary optimal one. In this work, we show that an informed refinement strategy is critical in theory and practice. We demonstrate that it is possible to execute all optimal abstract plans in the concrete task simultaneously, and present methods to minimize the time and number of refinement steps until we find a concrete solution. The resulting algorithm solves more tasks than the previous state of the art for Cartesian CEGAR, both during refinement and when used as a heuristic in an A* search.",David Speck Jendrik Seipp
MTS229,Optimising the Stability in Plan Repair via Compilation,"Plan repair is the problem of solving a given planning problem by using a solution plan of a similar problem. Plan repair problems can arise in execution contexts, that is, when an agent performing the plan has to deal with some unexpected contingency that makes the given plan invalid. Repairing a plan works often much better than replanning from scratch, and is crucial when plans have to be kept stable. There is no planning system until now that guarantees to find plans at the minimum distance from an input plan. This paper presents the first approach to such a problem; we indeed introduce a simple compilation scheme that converts a classical planning problem into another where optimal plans correspond to plans with the minimum distance from an input plan. Our experiments using a number of planners show that such a simple approach can solve the plan repair problem optimally and more effectively than replanning from scratch for a large number of cases. Last but not least, the approach proves competitive with LPG-ADAPT.",Alessandro Saetti Enrico Scala
MTS264,Assignment and Prioritization of Tasks with Uncertain Durations for Satisfying Makespans in Decentralized Execution,"Task assignment under execution uncertainty and temporal/resource constraints is a standard problem for many organizations. Existing approaches in the AI planning & scheduling and operations research literature predominantly focus on dynamic controllability, and non-preemptive execution of tasks. Such solutions are appropriate for teams of agents under tight control requirements. However, in most organizations with human teams, once tasks have been assigned, humans tend to execute their assignments without a constant central oversight (which is needed for dynamic controllability). 

In this paper we define a problem in which execution of tasks is distributed (without central oversight), and assumes humans can preempt their tasks when other tasks of higher priority are ready to be worked on. We present two algorithms based on Tabu search and Monte Carlo Tree Search to assign and prioritize tasks for such problems. Experimental results show the improved efficacy of these approaches for this problem setting over non-preemptive strategies.",Sriram Gopalakrishnan Daniel Borrajo
MTS33,Loopless Top-K Planning,"In top-k planning, the objective is to determine a set of k cheapest plans that provide several good alternatives to choose from. Such a solution set often contains plans that visit at least one state more than once. Depending on the application, plans with such loops are of little importance because they are dominated by a loopless representative and can prevent more meaningful plans from being found.

In this paper, we motivate and introduce loopless top-k planning. We show how to enhance the state-of-the-art symbolic top-k planner, symK, to obtain an efficient, sound and complete algorithm for loopless top-k planning. An empirical evaluation shows that our proposed approach has a higher k-coverage than a generate-and-test approach that uses an ordinary top-k planner, which we show to be incomplete in the presence of zero-cost loops.",Julian von Tschammer Robert Mattmüller David Speck
MTS65,Who Needs These Operators Anyway: Top Quality Planning with Operator Subset Criteria,"Top-quality planning in general and quotient top-quality planning in particular deal with producing multiple high-quality plans while allowing for their efficient generation, skipping equivalent ones. Prior work has explored one equivalence relation, considering two plans to be equivalent if their operator multi-sets are equal. This allowed omitting plans that are reorderings of previously found ones. However, the resulting sets of plans were still large, in some domains even infinite.
In this paper, we consider a different relation: two plans are related if one's operator multiset is a subset of the other's. We propose novel reformulations that forbid plans that are related to the given ones. While the new relation is not transitive and thus not an equivalence relation, we can define a new subset top-quality planning problem, with finite size solution sets. We formally prove that these solutions can be obtained by exploiting the proposed reformulations. Our empirical evaluation shows that solutions to the new problem can be found for more tasks than unordered top-quality planning solutions. Further, the results shows that the solution sizes significantly decrease, making the new approach more practical, particularly in domains with redundant operators.",Michael Katz Shirin Sohrabi
PL119,"Learning General Optimal Policies with Graph Neural Networks: Expressive Power, Transparency, and Limits","It has been recently shown that general policies for many classical planning domains can be expressed and learned in terms of a pool of features defined from the domain predicates using a description logic grammar. At the same time, most description logics correspond to a fragment of k-variable counting logic (C_k) for k=2, that has been shown to provide a tight characterization of the expressive power of graph neural networks. In this work, we make use of these results to understand the power and limits of using graph neural networks (GNNs) for learning optimal general policies over a number of tractable planning domains where such policies are known to exist. For this, we train a simple GNN in a supervised manner to approximate the optimal value function V*(s) of a number of sample states s. As predicted by the theory, it is observed that general optimal policies are obtained in domains where general optimal value functions can be defined with C_2 features but not in those requiring more expressive C_3 features. In addition, it is observed that the features learned are in close correspondence with the features needed to express V* in closed form. The theory and the analysis of the domains let us understand the features that are actually learned as well as those that cannot be learned in this way, and let us move in a principled manner from a combinatorial optimization approach to learning general policies to a potentially, more robust and scalable approach based on deep learning.",Simon Ståhlberg Blai Bonet Hector Geffner
PL145,Verifiable and Compositional Reinforcement Learning Systems,"We propose a framework for verifiable and compositional reinforcement learning (RL) in which a collection of RL subsystems, each of which learns to accomplish a separate subtask, are composed to achieve an overall task. The framework consists of a high-level model, represented as a parametric Markov decision process (pMDP) which is used to plan and to analyze compositions of subsystems, and of the collection of low-level subsystems themselves. By defining interfaces between the subsystems, the framework enables automatic decompositions of task specifications, e.g., reach a target set of states with a probability of at least 0.95, into individual subtask specifications, i.e. achieve the subsystem's exit conditions with at least some minimum probability, given that its entry conditions are met. This in turn allows for the independent training and testing of the subsystems; if they each learn a policy satisfying the appropriate subtask specification, then their composition is guaranteed to satisfy the overall task specification. Conversely, if the subtask specifications cannot all be satisfied by the learned policies, we present a method, formulated as the problem of finding an optimal set of parameters in the pMDP, to automatically update the subtask specifications to account for the observed shortcomings. The result is an iterative procedure for defining subtask specifications, and for training the subsystems to meet them. As an additional benefit, this procedure allows for particularly challenging or important components of an overall task to be identified automatically, and focused on, during training. Experimental results demonstrate the presented framework's novel capabilities in both discrete and continuous RL settings. A collection of RL subsystems are trained, using proximal policy optimization algorithms, to navigate different portions of a labyrinth environment. A cross-labyrinth task specification is then decomposed into subtask specifications. Challenging portions of the labyrinth are automatically avoided if their corresponding subsystems cannot learn satisfactory policies within allowed training budgets. Unnecessary subsystems are not trained at all. The result is a compositional RL system that efficiently learns to satisfy task specifications.",Cyrus Neary Christos Verginis Murat Cubuktepe Ufuk Topcu
PL209,Distributed Fleet Management in Noisy Environments via Model-Predictive Control,"We consider dynamic route planning for a fleet of Autonomous Mobile Robots (AMRs) doing fetch and carry tasks on a shared factory floor. In this paper, we propose Stochastic Work Graphs (SWG) as a formalism for capturing the semantics of such distributed and uncertain planning problems. We encode SWGs in the form of a Euclidean Markov Decision Process (EMDP) in the tool Uppaal Stratego, which employs Q-Learning to synthesize near-optimal plans. Furthermore, we deploy the tool in an online and distributed fashion to facilitate scalable, rapid replanning. While executing their current plan, each AMR generates a new plan incorporating updated information about the other AMRs positions and plans. We propose a two-layer Model Predictive Controller-structure (waypoint and station planning), each individually solved by the Q-learning-based solver. We demonstrate our approach using ARGoS3 large-scale robot simulation, where we simulate the AMR movement and observe an up to 27.5% improvement in makespan over a greedy approach to planning. To do so, we have implemented the full software stack, translating observations into SWGs and solving those with our proposed method. In addition, we construct a benchmark platform for comparing planning techniques on a reasonably realistic physical simulation and provide this under the MIT open-source license.",Simon Bøgh Peter Gjøl Jensen Martin Kristjansen Kim Guldstrand Larsen Ulrik Nyman
PL212,Inferring Probabilistic Reward Machines from Non-Markovian Reward Signals for Reinforcement Learning,"The success of reinforcement learning in typical settings is predicated on Markovian assumptions on the reward signal by which an agent learns optimal policies. In recent years, the use of reward machines has relaxed this assumption by enabling a structured representation of non-Markovian rewards. In particular, such representations can be used to augment the state space of the underlying decision process, thereby facilitating non-Markovian reinforcement learning. However, these reward machines cannot capture the semantics of stochastic reward signals. In this paper, we make progress on this front by introducing probabilistic reward machines (PRMs) as a representation of non-Markovian stochastic rewards. We present an algorithm to learn PRMs from the underlying decision process and prove results around its correctness and convergence.",Taylor Dohmen Noah Topper George Atia Andre Beckus Ashutosh Trivedi Alvaro Velasquez
PL232,Reinforcement Learning of Dispatching Strategies for Large-Scale Industrial Scheduling,"Scheduling is an important problem for many applications, including manufacturing, transportation, or cloud computing. 
Unfortunately, most of the scheduling problems occurring in practice are intractable and, therefore, solving large industrial instances is very time-consuming.
Heuristic-based dispatching methods can compute schedules in an acceptable time, but construction of a heuristic allowing for a satisfactory solution quality is a tedious process.
This work introduces a method to automatically learn dispatching strategies from only a few training instances using reinforcement learning.
Evaluation results obtained on real-world, large-scale instances of a resource-constrained project scheduling problem taken from the literature show that the learned dispatching heuristic generalizes to unseen instances and produces high-quality schedules within seconds.
As a result, our approach significantly outperforms state-of-the-art combinatorial optimization techniques in terms of solution quality and computation time.",Pierre Tassel Benjamin Kovács Martin Gebser Konstantin Schekotihin Wolfgang Kohlenbrein Philipp Schrott-Kostwein
PL282,Tuning the Hyperparameters of Anytime Planning: A Metareasoning Approach with Deep Reinforcement Learning,"Anytime planning algorithms often have hyperparameters that can be tuned at runtime to optimize their performance.  While work on metareasoning has focused on when to interrupt an anytime planner and act on the current plan, the scope of metareasoning can be expanded to tuning the hyperparameters of the anytime planner at runtime. This paper introduces a general, decision-theoretic metareasoning approach that optimizes both the stopping point and hyperparameters of anytime planning. We begin by proposing a generalization of the standard meta-level control problem for anytime algorithms. We then offer a meta-level control technique that monitors and controls an anytime algorithm using deep reinforcement learning. Finally, we show that our approach boosts performance on a common benchmark domain that uses anytime weighted A* to solve a range of heuristic search problems and a mobile robot application that uses RRT* to solve motion planning problems.",Abhinav Bhatia Justin Svegliato Samer Nashed Shlomo Zilberstein
PL304,Multi-Agent Tree Search with Dynamic Reward Shaping,"Sparse rewards and their representation in multi-agent domains remains a challenge for the development of multi-agent planning systems. While techniques from formal methods can be adopted to represent the underlying planning objectives, their use in facilitating and accelerating learning has witnessed limited attention in multi-agent settings. Reward shaping methods that leverage such formal representations in single-agent settings are typically static in the sense that the artificial rewards remain the same throughout the entire learning process. In contrast, we investigate the use of such formal objective representations to define novel reward shaping functions that capture the learned experience of the agents. More specifically, we leverage the automaton representation of the underlying team objectives in mixed cooperative-competitive domains such that each automaton transition is assigned an expected value proportional to the frequency with which it was observed in successful trajectories of past behavior. This form of dynamic reward shaping is proposed within a multi-agent tree search architecture wherein agents can simultaneously reason about the future behavior of other agents as well as their own future behavior.",Alvaro Velasquez Brett Bissey Lior Barak Daniel Melcer Andre Beckus Ismail Alkhouri George Atia
PL36,Beyond Value: CheckList for Testing Inferences in Planning-Based RL,"Reinforcement learning (RL) agents are commonly evaluated via their expected value over a distribution of test scenarios. Unfortunately, this evaluation approach provides limited evidence for post-deployment generalization beyond the test distribution. In this paper, we address this limitation by extending the recent CheckList testing methodology from natural language processing to planning-based RL. Specifically, we consider testing RL agents that make decisions via online tree search using a learned transition model and value function. The key idea is to improve the assessment of future performance via a CheckList approach for exploring and assessing the agent's inferences during tree search. The approach provides the user with an interface and general query-rule mechanism for identifying potential inference flaws and validating expected inference invariances. We present a user study involving knowledgeable AI researchers using the approach to evaluate an agent trained to play a complex real-time strategy game. The results show the approach is effective in allowing users to identify previously-unknown flaws in the agent's reasoning. In addition, our analysis provides insight into how AI experts use this type of testing approach, which may help improve future instantiations.",Kin-Ho Lam Delyar Tabatabai Jed Irvine Donald Bertucci Anita Ruangrotsakun Minsuk Kahng Alan Fern
PL56,Reinforcement Learning for Classical Planning: Viewing Heuristics as Dense Reward Generators,"Recent advances in reinforcement learning (RL) have led to a growing interest in applying RL to classical planning domains or applying classical planning methods to some complex RL domains. However, the long-horizon goal-based problems found in classical planning lead to sparse rewards for RL, making direct application inefficient. In this paper, we propose to leverage domain-independent heuristic functions commonly used in the classical planning literature to improve the sample efficiency of RL. These classical heuristics act as dense reward generators to alleviate the sparse-rewards issue and enable our RL agent to learn domain-specific value functions as residuals on these heuristics, making learning easier. Correct application of this technique requires consolidating the discounted metric used in RL and the non-discounted metric used in heuristics. We implement the value functions using Neural Logic Machines, a neural network architecture designed for grounded first-order logic inputs. We demonstrate on several classical planning domains that using classical heuristics for RL allows for good sample efficiency compared to sparse-reward RL. We further show that our learned value functions generalize to novel problem instances in the same domain. The source code and the appendix are available at github.com/ibm/pddlrl and arxiv.org/abs/2109.14830.",Clement Gehring Masataro Asai Rohan Chitnis Tom Silver Leslie Kaelbling Shirin Sohrabi Michael Katz
PL66,Is Policy Learning Overrated?: Width-Based Planning and Active Learning for Atari,"Width-based planning has shown promising results on Atari 2600 games using pixel input, while using substantially fewer environment interactions than reinforcement learning. Recent width-based approaches have computed feature vectors for each screen using a hand designed feature set (Rollout-IW) or a variational autoencoder trained on game screens (VAE-IW), and prune screens that do not have novel features during the search. We propose Olive (Online-VAE-IW), which updates the VAE features online using active learning to maximize the utility of screens observed during planning. Experimental results across 55 Atari games demonstrate that it outperforms Rollout-IW by 42-to-11 and VAE-IW by 32-to-20. Moreover, Olive outperforms existing work based on policy-learning (π-IW, DQN) trained with 100 times the training budget by 30-to-22 and 31-to-17, and a state of the art data-efficient reinforcement learning (EfficientZero) trained with the same training budget and ran with 1.8 times the planning budget by 18-to-7 in the Atari 100k benchmark, without any policy learning. The source code and the appendix are available at github.com/ibm/atari-active-learning and arxiv.org/abs/2109.15310 .",Benjamin Ayton Masataro Asai
PL93,TempAMLSI: Temporal Action Model Learning Based on STRIPS Translation,"Hand-encoding PDDL domains is generally considered difficult, tedious and error-prone. The difficulty is even greater when temporal domains have to be encoded. Indeed, actions have a duration and their effects are not instantaneous. In this paper, we present TempAMLSI, an algorithm based on the AMLSI approach to learn temporal domains. TempAMLSI is the first approach able to learn temporal domains with single hard envelopes, and TempAMLSI is the first approach able to deal with both partial and noisy observations. We show experimentally that TempAMLSI learns accurate temporal domains, i.e., temporal domains that can be used without human proofreading to solve new planning problems with different forms of action concurrency.",Maxence Grand Damien Pellier Humbert Fiorino
PLS110,Neural Network Heuristic Functions for Classical Planning: Bootstrapping and Comparison to Other Methods,"How can we train neural network (NN) heuristic functions for classical
planning, using only states as the NN input? Prior work addressed this
question by (a) per-instance imitation learning and/or (b) per-domain
learning. The former limits the approach to instances small enough for
training data generation, the latter to domains where the necessary
knowledge generalizes across instances.  Here we explore three methods
for (a) that make training data generation scalable through
bootstrapping and approximate value iteration. In particular, we
introduce a new bootstrapping variant that estimates search effort
instead of goal distance, which as we show converges to the perfect
heuristic under idealized circumstances. We empirically compare these
methods to (a) and (b), aligning three different NN heuristic function
learning architectures for cross-comparison in an experiment of
unprecedented breadth in this context.  Key lessons are that our
methods and imitation learning are highly complementary; that
per-instance learning often yields stronger heuristics than per-domain
learning; and the LAMA planner is still dominant but our methods
outperform it in one benchmark domain.",Patrick Ferber Florian Geißer Felipe Trevizan Malte Helmert Joerg Hoffmann
PLS158,Learning Multi-Agent Action Coordination via Electing First-Move Agent,"Learning to coordinate actions among agents is essential in complicated multi-agent systems. Prior works are constrained mainly by the assumption that all agents act simultaneously, and asynchronous action coordination between agents is rarely considered. This paper introduces a bi-level multi-agent decision hierarchy for coordinated behavior planning. We propose a novel election mechanism in which we adopt a graph convolutional network to model the interaction among agents and elect a first-move agent for asynchronous guidance. We also propose a dynamically weighted mixing network to effectively reduce the misestimation of the value function during training. This work is the first to explicitly model the asynchronous multi-agent action coordination, and this explicitness enables to choose the optimal first-move agent. The results on Cooperative Navigation and Google Football demonstrate that the proposed algorithm can achieve superior performance in cooperative environments. Our code is available at https://github.com/Amanda-1997/EFA-DWM.",Jingqing Ruan Linghui Meng Xuantang Xiong Dengpeng Xing Bo Xu
PLS175,DOMA: Deep Smooth Trajectory Generation Learning for Real-Time UAV Motion Planning,"In this paper, we present a Deep Reinforcement Learning (DRL) based real-time smooth UAV motion planning method for solving catastrophic flight trajectory oscillation issues. By formalizing the original problem as a linear mixture of dual-objective optimization, a novel Deep smOoth Motion plAnning (DOMA) algorithm is proposed, which adopts an alternative layer-by-layer gradient descending optimization approach with the major gradient and the DOMA gradient applied separately. Afterward, the mix weight coefficient between the two objectives is also optimized adaptively. Experimental result reveals that the proposed DOMA algorithm outperforms baseline DRL-based UAV motion planning algorithms in terms of both learning efficiency and flight motion smoothness. Furthermore, the UAV safety issue induced by trajectory oscillation is also addressed.",Jin Yu Haiyin Piao Yaqing Hou Li Mo Xin Yang Deyun Zhou
PLS314,Active Grammatical Inference for Non-Markovian Planning,"Planning in finite stochastic environments is canonically posed as a Markov decision process where the transition and reward structures are explicitly known. Reinforcement learning (RL) lifts the explicitness assumption by working with sampling models instead. Further, with the advent of reward machines, we can relax the Markovian assumption on the reward. Angluin's active grammatical inference algorithm L* has found novel application in explicating reward machines for non-Markovian RL. We propose maintaining the assumption of explicit transition dynamics, but with an implicit non-Markovian reward signal, which must be inferred from experiments. We call this setting non-Markovian planning, as opposed to non-Markovian RL. The proposed approach leverages L* to explicate an automaton structure for the underlying planning objective. We exploit the environment model to learn an automaton faster and integrate it with value iteration to accelerate the planning. We compare against recent non-Markovian RL solutions which leverage grammatical inference, and establish complexity results that illustrate the difference in runtime between grammatical inference in planning and RL settings.",Noah Topper George Atia Ashutosh Trivedi Alvaro Velasquez
351,,"Many AI applications involve the interaction of multiple autonomous agents, requiring those agents to reason about their own beliefs, as well as those of other agents. However, planning involving nested beliefs is known to be computationally challenging. In this work, we address the task of synthesizing plans that necessitate reasoning about the beliefs of other agents. We plan from the perspective of a single agent with the potential for goals and actions that involve nested beliefs, non-homogeneous agents, co-present observations, and the ability for one agent to reason as if it were another. We formally characterize our notion of planning with nested belief, and subsequently demonstrate how to automatically convert such problems into problems that appeal to classical planning technology for solving efficiently. Our approach represents an important step towards applying the well-established field of automated planning to the challenging task of planning involving nested beliefs of multiple agents.",
353,,"Research on preventative rail maintenance to date majors on small or artificial problem instances, not applicable to real-world use cases. This article tackles large, real-world rail maintenance scheduling problems. Maintenance costs and availability of the infrastructure need to be optimized, while adhering to a set of complex constraints. We develop and compare three generic approaches: an evolution strategy, a greedy meta-heuristic, and a hybrid of the two. As a case study, we schedule major preventive maintenance of a full year in the complete rail infrastructure of the Netherlands, one of the busiest rail networks of Europe. Empirical results on two real-world datasets show the hybrid approach delivers high-quality schedules.",
365,,"Multi-robot systems must be able to maintain performance when robots get delayed during execution. For mobile robots, one source of delays is congestion. Congestion occurs when robots deployed in shared physical spaces interact, as robots present in the same area simultaneously must manoeuvre to avoid each other. Congestion can adversely affect navigation performance, and increase the duration of navigation actions. In this paper, we present a multi-robot planning framework which utilises learnt probabilistic models of how congestion affects navigation duration. Central to our framework is a probabilistic reservation table which summarises robot plans, capturing the effects of congestion. To plan, we solve a sequence of single-robot time-varying Markov automata, where transition probabilities and rates are obtained from the probabilistic reservation table. We also present an iterative model refinement procedure for accurately predicting execution-time robot performance. We evaluate our framework with extensive experiments on synthetic data and simulated robot behaviour.",
366,,"Temporal planning often involves numeric effects that are directly proportional to their actions duration. These include continuous effects, where a numeric variable is subjected to a rate of change while the action is being executed, and discrete duration-dependent effects, where the variable is updated instantaneously but the magnitude of such change is computed from the actions duration. When these effects are linear, stateoftheart temporal planners often make use of Linear Programming to ensure that these numeric updates are consistent with the chosen start times and durations of the plans actions. This is typically done for each evaluated state as part of the search process. This exhaustive approach is not scalable to solve real-world problems that require long plans, because the linear programs size becomes larger and slower to solve. In this work we propose techniques that minimise this overhead by computing these checks more selectively and formulating linear programs that have a smaller footprint. The effectiveness of these techniques is demonstrated on domains that use a mix of discrete and continuous effects, which is typical of real-world planning problems. The resultant planner also outperforms most state-of-the-art temporal-numeric and hybrid planners, in terms of both coverage and scalability.",
367,,"In automated planning, the need for explanations arises when there is a mismatch between a proposed plan and the users expectation. We frame Explainable AI Planning as an iterative plan exploration process, in which the user asks a succession of contrastive questions that lead to the generation and solution of hypothetical planning problems that are restrictions of the original problem. The object of the exploration is for the user to understand the constraints that govern the original plan and, ultimately, to arrive at a satisfactory plan.

We present the results of a user study that demonstrates that when users ask questions about plans, those questions are usually contrastive, i.e. ""why A rather than B?"". We use the data from this study to construct a taxonomy of user questions that often arise during plan exploration.

Our approach to iterative plan exploration is a process of successive model restriction. Each contrastive user question imposes a set of constraints on the planning problem, leading to the construction of a new hypothetical planning problem as a restriction of the original. Solving this restricted problem results in a plan that can be compared with the original plan, admitting a contrastive explanation.

We formally define model-based compilations in PDDL2.1 for each type of constraint derived from a contrastive user question in the taxonomy, and empirically evaluate the compilations in terms of computational complexity.

The compilations were implemented as part of an explanation framework supporting iterative model restriction. We demonstrate its benefits in a second user study.",
368,,"In this paper, we study the computational complexity of action-based temporal planning interpreted over dense time. When time is assumed to be discrete, the problem is known to be EXPSPACE-complete. However, the official PDDL 2.1 semantics and many implementations interpret time as a dense domain. This work provides several results about the complexity of the problem, focusing on some particularly interesting cases: whether a minimum amount epsilon of separation between mutually exclusive events is given, in contrast to the separation being simply required to be non-zero, and whether or not actions are allowed to overlap already running instances of themselves. We prove the problem to be PSPACE-complete when self-overlap is forbidden, whereas, when it is allowed, it becomes EXPSPACE-complete with epsilon-separation and even undecidable with non-zero separation. These results clarify the computational consequences of different choices in the definition at the core of the PDDL 2.1 semantics, which have been vague until now.",
369,,"When working in an unfamiliar online environment, it can be helpful to have an observer that can intervene and guide a user toward a desirable outcome while avoiding undesirable outcomes or frustration. The Intervention Problem is deciding when to intervene in order to help a user. The Intervention Problem is similar to, but distinct from, Plan Recognition because the observer must not only recognize the intended goals of a user but also when to intervene to help the user when necessary. We formalize a family of Intervention Problems and show that how these problems can be solved using a combination of Plan Recognition methods and classification algorithms to decide whether to intervene. For our benchmarks, the classification algorithms dominate three recent Plan Recognition approaches. We then generalize these results to Human-Aware Intervention, where the observer must decide in real time whether to intervene human users solving a cognitively engaging puzzle. Using a revised feature set more appropriate to human behavior, we produce a learned model to recognize when a human user is about to trigger an undesirable outcome. We perform a human-subject study to evaluate the Human-Aware Intervention. We find that the revised model also dominates existing Plan Recognition algorithms in predicting Human-Aware Intervention.",
371,,"The merge-and-shrink framework has been introduced as a
general approach for defining abstractions of large state spaces
arising in domain-independent planning and related areas. The
distinguishing characteristic of the merge-and-shrink approach is
that it operates directly on the factored representation of state
spaces, repeatedly modifying this representation through
transformations such as shrinking (abstracting a factor of
the representation), merging (combining two factors),
label reduction (abstracting the way in which different
factors interact), and pruning (removing states or
transitions of a factor).

We provide a novel view of the merge-and-shrink framework as a
``toolbox'' or ``algebra'' of transformations on factored transition
systems, with the construction of abstractions as only one possible
application. For each transformation, we study desirable properties
such as conservativeness (overapproximating the original
transition system), inducedness (absence of spurious states
and transitions), and refinability (reconstruction of paths
in the original transition system from the transformed one). We
provide the first complete characterizations of the conditions under
which these desirable properties can be achieved. We also provide
the first full formal account of factored mappings, the
mechanism used within the merge-and-shrink framework to establish
the relationship between states in the original and transformed
factored transition system.

Unlike earlier attempts to develop a theory for merge-and-shrink,
our approach is fully compositional: the properties of a sequence of
transformations can be entirely understood by the properties of the
individual transformations involved. This aspect is key to the use
of merge-and-shrink as a general toolbox for transforming factored
transition systems. New transformations can easily be added to our
theory, with compositionality taking care of the seamless
integration with the existing components. Similarly, new properties
of transformations can be integrated into the theory by showing
their compositionality and studying under which conditions they are
satisfied by the building blocks of merge-and-shrink.",
372,,"Knowledge-based programs contain both world-altering actions, which upon execution change the state of the world, and sensing actions, which upon execution change the knowledge state of the agent. Knowledge-based programming has been proposed as an alternative to planning, since programs allow solving families of planning problems. Notwithstanding, agents equipped with a variety of knowledge-based procedures can compose these procedures to achieve goals, exhibiting greater degrees of flexibility. Optimized state-of-the-art planners, unfortunately, cannot be used directly to compose programs since they require operators (not programs), defined by preconditions and effects. In this article we study how to compute preconditions and effects of knowledge-based programs in order to allow state-of-the-art planners to construct plans with knowledge-based programs as building blocks. We study the problem in the language of the situation calculus, appealing to Golog to represent our programs. To this end, we propose an offline execution semantics for Golog programs with sensing. We then propose a compilation method that transforms our action theory with programs into a new theory where programs are replaced by primitive actions. This enables us to use state-of-the-art, operator-based planning techniques to plan with programs that sense for a restricted but compelling class of problems. Finally, we discuss the applicability of these results to existing operator-based planners that support sensing and illustrate the computational advantage of planning with programs that sense via an experiment.",
373,,"Reinforcement learning (RL) methods usually treat reward functions as black boxes. As such, these methods must extensively interact with the environment in order to discover rewards and optimal policies. In most RL applications, however, users have to program the reward function and, hence, there is the opportunity to make the reward function visible -- to show the reward function's code to the RL agent so it can exploit the function's internal structure to learn optimal policies in a more sample efficient manner. In this paper, we show how to accomplish this idea in two steps. First, we propose reward machines, a type of finite state machine that supports the specification of reward functions while exposing reward function structure. We then describe different methodologies to exploit this structure to support learning, including automated reward shaping, task decomposition, and counterfactual reasoning with off-policy learning. Experiments on tabular and continuous domains, across different tasks and RL agents, show the benefits of exploiting reward structure with respect to sample efficiency and the quality of resultant policies. Finally, by virtue of being a form of finite state machine, reward machines have the expressive power of a regular language and as such support loops, sequences and conditionals, as well as the expression of temporally extended properties typical of linear temporal logic and non-Markovian reward specification.",